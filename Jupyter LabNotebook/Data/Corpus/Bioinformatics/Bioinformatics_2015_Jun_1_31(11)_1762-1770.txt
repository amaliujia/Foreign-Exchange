1 Introduction
Most biological processes are dynamic and analysis of time series data is necessary to understand them. Recent advances in high-throughput sequencing (HTS) technologies have provided new experimental approaches to collect genome-wide time series. For example, experimental evolution now uses a new evolve and re-sequencing (ER) approach to understand which genes are targeted by selection and how (; ). Such experiments enable phenotypic divergence to be forced in response to changes in only few environmental conditions in the laboratory while other conditions are kept constant. The evolved populations are then subjected to HTS.

Experimental evolution in microorganisms has focused on the fate new mutations. For example, in Escherichia coli () and Saccharomyces cerevisae () new mutations were studied. In contrast, ER experiments with sexually reproducing multicellular organisms address selection on standing variation and allele frequency changes (AFCs) in small populations where drift plays an important role. For example, for Drosophila melanogaster (Dmel), several phenotypic traits, such as accelerated development (), body size variation (), hypoxia-tolerance () and temperature adaptation () have been investigated. Motivated by these experimental studies, we believe that experimental evolution combined with HTS supplies a good basis for studying AFC through time series molecular data.

To perform allele frequency comparisons, pairwise statistical tests between base and evolved populations were typically carried out.  combined Fisher’s exact tests with a sliding-window approach to identify genomic regions that show allele frequency differences between populations selected for accelerated development and controls without direct selection.  developed a pairwise summary statistic, called ‘diff-Stat’ to estimate the observed distribution of allele frequency differences and compared this to the expected distribution without selection.  identify single nucleotide polymorphisms (SNPs) with a consistent AFC among replicates by performing a Cochran-Mantel-Haenszel test (CMH) (). The latter is an extension of the Fisher’s exact test to multiple replicates. All aforementioned statistical methods are based on pairwise comparisons between the base and evolved populations and they do not take full advantage of the time series data now available.  developed a method to analyze time series data based on population genetic models and estimated the effective population size Ne of a bacteriophage from a single locus.  derived a model for time series data from large populations of microorganisms () where drift can be ignored and the population allele frequencies evolve ‘quasi-deterministically’. Here, we propose an alternative Gaussian process (GP) based approach to study AFCs over the entire time series experiment genome-wide for small populations ().

GP is a non-parametric statistical model that is extremely well suited for modelling HTS time series data, which usually have relatively few time points that may be irregularly sampled. Recently, there have been some works applying GP models with parameters describing the process of evolution (e.g.  account for phylogenetic relationships,  for effective population size). GPs have also recently been applied to gene expression time series by a number of authors (; ; ; ; ; ; ; ; ; ; ; ). In differential analysis, GPs have been applied to detect differences in gene expression time series in a two-sample setting by  and for detecting significant changes by . Although these methods provide a sensible basis for detecting the changing alleles, they fail to properly take into account all aspects of the available HTS data, such as differences in sequencing depth between different alleles and time points. These differences can have a huge impact in the reliability of different measured allele frequencies and taking them into account is vital for achieving good accuracy with the available short time series.

2 Methods
To identify the candidate alleles which evolve under selection, we model the allele frequencies by GP regression. We fit time-dependent and time-independent GP models and rank the alleles according to their corresponding Bayes factors (BFs), i.e. the ratio of the marginal likelihoods under the different models.

GPs provide a convenient approach for modelling short time series. However, when applying them to a large number of short parallel time series as in many genomic applications, naive application leads to overfitting or underfitting in some examples. Although these problems are rare, the bad examples can easily dominate the ranking. We overcome these challenges by excluding non-sensical parameter values, for example using a good variance model that can be incorporated into the GP models.

2.1 Data and preprocessing
In the following, we use the term SNP for the markers and alleles under study, but the methods can be applied to any features whose abundance can be quantified in a similar manner. We consider SNPs that are bi-allelic for a specific position of the genome in a population. Multi-allelic SNPs, however, exist but are rare and likely to be sequencing errors (). Multi-allelic cases can be treated by simply ignoring the least frequent allele or transformed to bi-allelic site by summing up the frequencies of the most infrequent alleles. Here, we assumed that only two of the alleles from (A, T, C, G) can be observed at each SNP position. After determining the abundances of these two specific alleles, we model the time dependency of the rising allele’s frequency over several generations. We will refer to generations as time points for simplicity.

We denote the replicate index of each observation by rj and the time point by tj, j = 1,…, J, with J denoting the total number of observations. For each of these points, we assume HTS reads have been aligned to a reference genome with yij reads with a specific allele at SNP position i. We use nij to denote the total sequencing depth at the position.

2.2 Mean and variance inference: beta-binomial model
We model yij as a draw from a binomial distribution with parameters nij and pij:

where pij denotes the frequency of the specific allele in the population. We set a uniform Beta(1,1) prior on pij:

where α = 1, β = 1.

Since beta prior is conjugate to the binomial likelihood, the posterior distribution will also be a beta distribution:

where


Then, the posterior mean and variance of pij can be calculated as follows:


The inferred posterior means and posterior variances are used to fit the GP models as described in the following sections. As the results will show, this step is very important for incorporating the available uncertainty information into the GP models by taking into account different sequencing depths. For example, beta-binomial model assigns larger variances to the alleles with lower sequencing depths (). Moreover, the Beta(1,1) prior on pij leads to a symmetry in the posterior mean and variance. Therefore, the result of our method is not affected whichever allele is chosen from the alternative alleles.
Posterior standard deviations of the allele frequencies with sequencing depths 10, 30 and 60




2.3 GP regression
A GP is a collection of random variables, any finite number of which has a joint Gaussian distribution. We write

to denote that f(t) follows a GP with mean function  and covariance function . We let  be a vector of the noisy observations measured at points  satisfying

where ϵ is Gaussian observation noise with zero mean and a diagonal covariance matrix . To simplify the algebra, we assume the mean function m(t) = 0 and subtract the mean of y.

Gaussian processes allow marginalizing the latent function to obtain a marginal likelihood. The covariance function K and the noise covariance  depend on hyperparameters θ that can be estimated by maximizing the log marginal likelihood:

where  denotes the covariance matrix constructed by evaluating the covariance function at points t. It is also possible to compute the posterior mean and covariance at non-sampled time points , given the noisy observations y at sampled time points t. This is often useful for visualization purposes. We obtain ():

where



In our GP models, we use the squared exponential covariance matrix to model the underlying smooth function. The squared exponential covariance

has two parameters: the length scale, l, and the signal variance, . Length scale specifies the distance beyond which any two inputs become uncorrelated. A small length scale means that the function fluctuates very quickly, whereas a large length scale means that the function behaves like a constant function. Three example realizations generated with squared exponential covariance matrix can be seen in a.
Example realizations from GPs and noise processes with different covariance structures




In the standard GP model, the observation noise is assumed to be white: the noise at different time points is independent and identically distributed. The corresponding covariance matrix

is an identity matrix multiplied by the noise variance parameter, . Three example realizations generated with white noise covariance matrix can be seen in b.

2.4 Beta-binomial Gaussian process
The beta-binomial Gaussian process (BBGP) method combines beta-binomial model with the GP model in the sense that the posterior means and posterior variances of the frequencies, which are inferred by beta-binomial model, are used to fit the GP model by means of an additional noise covariance matrix which we call fixed beta-binomial (FBB) covariance matrix.

Returning to Section 2.2, let us denote the posterior mean and variance of pij by mij and , respectively. That is,


To fit the BBPG model, we assume

where  and . The mean  is eliminated by subtracting the mean from mij. Because of ΣFBB this is an approximation that may fail if nij vary significantly, but it speeds up inference significantly. The additional covariance

is a diagonal FBB covariance matrix which is used to include known variance information for each observation in the GP model. The elements of ΣFBB are determined by the posterior variances which are inferred from beta-binomial model in Section 2.2. Three example realizations generated with FBB covariance matrix can be seen in c, where larger variance values were inferred for the later time points.

2.5 BBGP-based test
We fit the ‘time-dependent’ BBGP model of  and a ‘time-independent’ model without the GP term  for each SNP i. As can be seen from the graphical models in , ‘time-independent’ model assumes that the observations are randomly generated around a constant mean with no temporal dependency, whereas ‘time-dependent’ model captures the dependency between the observations by the function , which follows a GP with the squared exponential covariance function. Thereby the parameters of the squared exponential covariance [KSE, ] in the time-dependent model and the white noise covariance [ΣW, ] in both models are fitted by maximizing the marginal likelihood. The FBB covariance [ΣFBB, ] does not contain any free hyperparameters. If the model is actually time independent, the length scale in the squared exponential covariance is estimated to be very large, which makes the maximum likelihood of the time-dependent model equivalent to that of time-independent model.  shows an example of the time-dependent (left) and time-independent (right) BBGP models.
Graphical models for the (a) time-dependent and (b) time-independent BBGP models


BBGP fits for the time-dependent and time-independent models for an example SNP taken from the real dataset (). Confidence regions are shown for ± 2 standard deviation. Similarly, error bars indicate ± 2 standard deviation (from FBB) interval. Replicates at the same time points are shifted by 0.5 for better visualization. Maximum likelihood estimates of the parameters: ; 




We maximize the log marginal likelihood functions for the models by scaled conjugate gradient method using the ‘gptk’ R package by . We use a grid search over the parameter space and initialize the parameters to the grid value with highest likelihood. We also set a lower bound equal to the shortest spacing between observations for the length scale parameter to avoid overfitting.

We compute the BF for SNP i as (; )

where  and  contain the maximum likelihood estimates of the hyperparameters in the corresponding BBGP models. BFs indicate the degree of the models to be ‘time dependent’ rather than ‘time independent’.

2.6 CMH test
We compare BBPG against the CMH test, which was used by  to identify alleles with consistent AFC across replicates. The CMH test has been proven to be the best-performing test statistic applied on HTS evolutionary data so far (). Therefore, we take it as the basis of comparison with BBGP.

CMH allows to test whether the joint odds ratio of replicated () allele counts in a  contingency table () is significantly different from one. Significant deviation from one implies dependence of allele counts between two time points that is consistent among replicates. The CMH tests pairwise observations of the two alternative allele counts  and . In our bi-allelic case  and . To compare the counts for all replicates  at the base (B) and the end (E) time points for each SNP position i, we denote  and . The CMH test statistic [see  and Supplementary Text Section S1] compares the cell counts in  to their null expected values and it follows a chi-squared distribution with one degree of freedom . We performed CMH tests on the simulated and real data for each SNP position independently, using the implementation of the software PoPoolation2 ().
2 × 2 contingency table of allele counts for the r-th replicate

	Base generation (B)	End generation (E)		
SNP
i
allele 1				
SNP
i
allele 2				
				


2.7 Simulations
To evaluate the performances of the BBGP and the CMH tests, we simulated data that mimic the dynamics of evolving Dmel populations at the genomic level. For this aim, we first simulated three sets of genome-scale data to evaluate the overall performances of the methods under the experimental design which is close to the natural settings. Additionally, we also carried out smaller size simulations on one chromosome arm to investigate the further influences of different parameter settings on the methods.

2.7.1 Whole-genome simulations
We carried out forward Wright-Fisher simulations of genome-wide allele frequency trajectories of populations using the MimicrEE simulation tool (). The initial haplotypes were taken from , and they capture the natural variation of Dmel population. By sampling from the initial set, we established r = 5 replicated base populations using H = 200 founder haplotypes and let each of them evolve for g = 60 generations at a constant census size of N = 1000. We used the spatially varying recombination rate defined for Dmel by . Low recombining regions were excluded from the simulations because of the elevated false-positive rate in these regions (). We followed the evolution of the total number of 19 39 941 autosomal SNPs among which 100 were selected with selection coefficient of s = 0.1 and semi-dominance (h = 0.5). Furthermore, we required the selected SNPs to have a starting frequency in the range , not to lose the minor allele in the course of time due to drift. We recorded the nucleotide counts for every second generation and performed Poisson sampling with λ = 45 (overall mean coverage in ) on the count data to produce coverage information (see Supplementary Text Section S2). We repeated the whole simulation experiment three times, each time using a different set of selected SNPs.

2.7.2 Single-chromosome-arm simulations
For experimental design, additional simulations were carried out on a single chromosome arm (∼16 Mb) with 25 selected SNPs to assess the performance under various parameter combinations, such as population size (N), number of founder haplotypes (H), selection coefficient (s), level of dominance (h), number of generations (g) and number of replicates (r). We defined a basic set up with parameter space close to that of the whole-genome simulations, i.e. , and investigated the effect on the performance when only one parameter is perturbed from its basic value.

2.8 Evaluation metrics
The methods were evaluated based on precision, recall and average precision (AP) (). Precision and recall are commonly used metrics to measure the fraction of relevant items that are retrieved when comparing ranking based methods. Precision and recall are defined as


The curve obtained by plotting the precision at every position in the ranked sequence of items as a function of recall is called the precision-recall curve. The area under the curve can be summarized using AP (), which is defined as the average of pre(k) after every returned selected SNP:

where N is the total number of SNPs and



3 Results
3.1 Simulated whole-genome data
We applied the BBGP and CMH on the genome-wide simulated data with different numbers of time points (i.e. generations) and replicates. To evaluate the effect of the number of time points used, we tested the method using subsets of different sizes of the nine time points  (see Supplementary Text Section S3 for details). We performed BBGP separately for each of the sampling schemes while CMH can only use two time points (first and last). All simulated SNPs were scored using BFs for the BBGP, and P-values for the CMH test (e.g. see Supplementary Fig. S1 for a graphical visualization of the scores).

To investigate the effect of the number of replicates (r), we chose up to five replicates at each sampled time point. We first performed CMH tests with all possible r-replicate combinations. We then applied BBGP only to the best performing replicate combinations of each size according to AP in the CMH evaluations. This strategy ensures a fair comparison between the methods as BBGP is always evaluated against the best CMH results. We also compared BBGP to the standard GP of  that does not use the FBB model variances using the same replicate combinations as BBGP with 6 time points.

As shown in  (see also Supplementary Figs. S2 and S3), BBGP achieves a higher AP than the standard GP and the CMH. Somewhat surprisingly, CMH seems to benefit very little from more replicates while the performance of the GP methods improves noticeably. The CMH is sensitive to the specific replicates included, as including the fifth replicate in the optimal sequence actually leads to worse performance than four replicates (Supplementary Fig. S3c and d). We did not observe similar behaviour with the GP methods. On average over all possible r-replicate combinations, adding more replicates helps the CMH as well (mean AP in ). The performance of the standard GP approaches that of BBGP as the number of replicates increases, which is consistent with the view that the stronger prior information from sequencing depth is most important when the data are otherwise scarce, as is often the case in real experiments. In contrast to more replicates, adding more time points improved BBGP's performance very little ().
APs for CMH, BBGP and standard GP with different number of replicates (r) and time points (t) in the whole-genome simulation. The best-performing r-replicate combination in the CMH test has been used in GP and BBGP, and the mean AP for CMH has been computed by taking the mean of the APs over all r-replicate combinations for r = 2,3,4,5. The corresponding precision–recall curves are shown in Supplementary Figures S2 and S3. Additionally, average AP for random ranking (line of no discrimination) is shown by a constant line at the true fraction of selected SNPs in the simulated data, i.e. 




We also investigated whether the two methods identify different types of selected SNPs. We calculated AFC for each SNP based on the average difference between the base and end populations across replicates. The CMH is sensitive to large AFCs, while the candidates detected by the BBGP have a much more uniform distribution of AFCs (Supplementary Fig. S5). In general, we would expect a uniform distribution of AFCs, as very large AFCs are only possible for SNPs with low starting frequency giving them the potential to rapidly increase. BBGP is much more accurate than CMH in all AFC classes as demonstrated by the performance breakdown in Supplementary Figure S6.

Furthermore, we performed a generalized CMH test (gCMH) that can be applied to more than two time points but requires a weighting scheme (Supplementary Text Section S1.1). As there is no straightforward way to find weights that accurately reflects natural selection, we used mid-ranks assigned to time points. The performance of the gCMH drops rapidly with increasing the number of time points and replicates (Supplementary Fig. S7), which might be due to a poor weighting scheme.

The performance of the methods can vary noticeably between different experiments depending on their difficulty. For example, there is a 10-fold difference in AP between Experiment 1 and Experiment 3 for both methods (Supplementary Fig. S4, see also  for the CMH), but the BBGP-based test consistently outperforms the CMH test.

The running time needed to analyze 1000 SNPs in a 4-replicate 6-time point setting is 30 min on a desktop running Ubuntu 12.04 with Intel(R) Xeon(R) CPU E3-1230 V2 at 3.30 GHz. 

3.2 Influence of parameter choice
For the purpose of experimental design, we investigated further parameter settings on the single chromosome arm of 2L.

3.2.1 Population size and number of founder haplotypes
In finite populations, genetic drift has a large impact on shaping the population allele frequencies. We studied the effect of census populations size (N) and the number of founder haplotypes (H). H can be thought as the number of different individuals (isofemale lines) in the base population. The populations were established by randomly choosing N individuals with replacement out of the H founders. The simulation results show that AP increases with increasing N (a). This has also been observed by  for the CMH test. The AP is the highest with the ratio of  in all cases (a, Supplementary Figs. S8–S10) and the BBGP consistently outperforms the CMH test.  reported that the true-positive rate for CMH test increases with H but the increment levels off with  for N = 1000.  detected a constant increase in the power to localize a candidate SNP; however, they used a different method and investigated different parameter settings not comparable to ours. We hypothesize that as more low-frequency variants are present in the population with , the selected SNPs with multiple linked backgrounds are competing with each other, resulting in an AP drop.
APs for different experimental designs. AP for random ranking is shown in (b) by a constant line at the true value of the ratio of selected SNPs in the simulated data, i.e. . Log scale was used on both axes for (a), (b), (d) and on the y-axis for (c). Other parameters are as in the basic setup in Section 2.7




3.2.2 Selection strength and level of dominance
We investigated the performance using various selection coefficients (s) and fixed semidominance (h = 0.5). For moderate and strong selection (s &gt; 0.01), the BBGP outperforms the CMH test (b, Supplementary Fig. S11). The BBGP reaches the highest precision at s = 0.1, whereas the CMH test is the most precise at s = 0.05 which is consistent with . For strong selection (s = 0.2) the precision drops for both methods. The performance decay is presumably due to interference between selected sites, known as the Hill–Robertson effect, i.e. linkage between sites under selection will reduce the overall effectiveness of selection in finite populations (). Also, we hypothesize that long-range associations become more apparent as the strength of selection increases (Supplementary Fig. S12) resulting in larger blocks rising in frequency together, which was also observed by .

For weak selection (), it becomes hard to distinguish between selection and drift in small populations. Thus, for low s, both methods perform rather poorly and the CMH has a slightly higher AP in these cases. However, for a more ideal parameter choice of  and a long runtime of the experiment (g = 120), the BBGP gains a large performance improvement over the CMH test for s = 0.01 (see Supplementary Figs. S13 and S14) even in the difficult scenario of weak selection.

We also simulated evolving populations using different levels of dominance (h). The following relative fitness values were used on genotypes AA, Aa and aa: , waa = 1, where s = 0.1. As h varies, we observed different behaviour of the methods. The AP of the CMH test increases as we are moving from complete recessivity (h = 0, recessive phenotype is selected) to complete dominance (h = 1, dominant phenotype is selected) (Supplementary Figs. S15 and S16). Selection on completely recessive allele results in a gradual initial change in AF with more rapid change in later generations and eventual fixation. In contrast, the change in AF of a completely dominant allele is initially rapid but never reaches fixation as the recessive allele is shielded from natural selection in the heterozygote. When the fitness of the heterozygote is intermediate between the two homozygotes (additivity, h = 0.5) the allele frequency trajectory is the combination of the aforementioned ones, i.e. rapid initial change and quick fixation. BBGP reaches the highest AP with the additive scenario and relatively high AP in the recessive case (Supplementary Fig. S15). When the dominant phenotype is selected () and the unfavoured allele stays present in the population at low frequency, it is likely to result in an inconsistent behaviour of replicates, which lower the power of the BBGP.

3.2.3 Number of replicates
In addition to the whole-genome experiments with a maximum of five replicates, we simulated up to r = 15 replicates for the single chromosome arm. We observed a constant increase in performance for the BBGP up to r = 6 (c, Supplementary Fig. S17). The AP kept increasing up to r = 12 but rather in a fluctuating manner and then dropped with adding even more replicates. Consistently with the whole-genome simulations, we did not observe a large performance improvement with increasing the number of replicates for the CMH test.

3.2.4 Length of the experiment and spacing of the samples
We also examined the performance with increasing the length of the experiments up to g = 120 generations. For longer experiments, more recombination events can happen, which uncouples linked sites letting them evolve independently. The AP rises rapidly for longer experiments (d, Supplementary Fig. S18). Thereby the performance gain is noticeably higher for the BBGP. We also investigated the spacing of the sampled time points () for the BBGP and observed similar pattern that of the whole-genome simulations, i.e. an intermediate number of sample time points is sufficient as shape of selected trajectories is simple.

3.3 Real data application
 applied ER methods on Dmel populations adapting to elevated temperature regime. They established base populations from isofemale lines collected in Portugal. The populations were propagated at a constant size of 1000 for 37 generations under fluctuating temperature regime (12h at 18°C and 12h at 28°C). DNA pools of 500 females (Pool-Seq) were sequenced at the following time points: three replicates at the base generation 0 (B); two replicates at generation 15, an additional replicate at generation 23 and 27; three replicates at the end generation 37 (E).

CMH tests were performed on a SNP-wise basis to identify significant AFCs between the B and E populations [see  and Supplementary Text Section S4]. We applied the BBGP method on 12 57 117 SNPs and compared the results with that of the B-E comparison of the CMH test. The overlap between the top 2000 candidate SNPs of the CMH and the BBGP was rather small (609 SNPs). However, the peaks of both methods covered the same regions ().
Manhattan plots of genome-wide SNP-values. (a)  for the CMH test B-E comparison. P-values below 1e−30 were clipped to 1e−30 on the plot. (b) ln (BFs) for the BBGP. Only those SNPs are indicated for which we calculated both the P-values and the BFs (we did not infer BFs for tri-allelic SNPs). A 1 Mb region was excluded from the analysis on 3R as a low-frequency haplotype spreads during the experiment. Previously, the chorion gene cluster on 3L was also excluded as this region has extremely high coverage (). Regions that were excluded from the analysis are shown in green. The red horizontal line indicates the top 2000 candidate cutoff. The common candidates among the top 2000 are highlighted in magenta.  shows how well the beta-binomial variance control can handle high coverage problem of the excluded region on 3L




The difference between the methods is illustrated with some example allele trajectories in Supplementary Figures S23–S25. BBGP emphasizes between-replicate consistency and sometimes picks candidate SNPs that start already at high frequency and go rapidly to fixation. On the other hand, CMH test assigns high ranks to SNPs with large frequency change and fails to detect between-replicate consistency if the fold change is otherwise low.

Using a gene set enrichment analysis (see Supplementary Text Section S5), we also found that the top ranked significantly enriched Gene Ontology categories were similar for both tests (Supplementary Tables S3 and S4, Supplementary Fig. S19). Furthermore,  shows how well the posterior beta-binomial variance inference can handle false signals resulting from uneven coverage. While the CMH test is misled by strong signal coming from high coverage of the chorion cluster with high copy number variation, the BBGP test does not falsely indicate signatures of selection (, green region on 3L).

Although Dmel generally has rather small levels of linkage, linkage disequilibrium (LD) might have built up during the course of the experiment. In fact, LD had a major effect on the number of candidate SNPs identified by the CMH as well as the BBGP test. As the flanking SNPs showed signs of hitchhiking, the observed AFC of the flanking SNPs were also significant (see also Manhattan plot for the simulated SNPs Supplementary Fig. S1), and this made it difficult to narrow down functionally important regions for thermoadaptation.

4 Discussion
Our results in detecting SNPs that are evolving under selection using a GP model clearly demonstrate the importance of careful modelling of the measurement uncertainty through a good noise model, in our case using the beta-binomial model of sequencing data. Especially when data are scarce, the BBGP approach leads to much higher accuracy than standard maximum likelihood estimation of noise variances. Incorporating the non-Gaussian likelihood directly to the GP would also be possible, but it would lead to computationally more demanding inference.

In terms of experimental design, the most effective way to improve performance is to use a larger population (N) and a larger number of founder haplotypes (H). As expected, alleles under moderate to strong selection (s = 0.05–0.1) are easier to detect than alleles changing under weak selection (). However, for very strong selection (), it is again hard to detect the causal SNPs. In a real experiment, the strength of selection might also not be known and often cannot be changed for the trait of interest. Adding more replicates can also help improve performance up to some point. Compared with the CMH test, the BBGP is clearly superior in utilizing additional replicates. We suspect this is because CMH assumes all replicates should have similar odds ratios between the two time points and this is not sufficiently satisfied by the noisy data. Longer experiments can help significantly (Supplementary Fig. S13), but the benefit of adding more intermediate time points seems smaller. This may be because the shape of selected trajectories is a simple sigmoid, and adding more points provides limited help in estimating them. The presented GP-based test is sensitive to SNPs with a consistent time-varying profile. A statistically more accurate model could be derived by assuming each replicate to follow an independent GP, but this would require different kind of constraints to differentiate between selection and drift, which may be difficult to formulate for multiple interacting SNPs. Exploring hierarchical GP models to capture the correct dependence structure is an interesting avenue of future research.

In a whole-genome experiment, LD between nearby markers and interactions between nearby selected SNPs are important confounders in identifying the selected markers. Especially for moderate-sized populations, the interactions can be problematic, leading to very large segments in the genome raising together in frequency (Supplementary Fig. S12). The issue does not appear when simulating only a single selected SNP (Supplementary Fig. S20), which strongly suggests it is caused by the interactions. The issue can be most effectively mitigated by using larger populations (Supplementary Fig. S21c and d). An artificially high recombination rate (Supplementary Fig. S21a and b) could also break the interactions. Working with larger fixed window sizes might not improve the performance as a substantial number of hitchhikers can still be found hundreds of kilobases from the selected SNPs (See Supplementary Fig. S22: The removal of nearby hitchhikers did not improve the AP noticeably). It is possible to extend the GP models for joint analysis of multiple SNPs, and this is clearly an important avenue of future research. This is potentially a further advantage of the GP, because it is much more difficult to similarly extend the frequentist tests.

5 Conclusion
In this article, we developed a new test that is based on combining GP models with a beta-binomial model of sequencing data, and compared it with the CMH test that allows the pairwise comparison of base and evolved populations across several replicates.

Our results demonstrate that GP models are well suited for analyzing quantitative genomic time series data because they can effectively utilize the available data, making good use of additional time points and replicates unhindered by uneven sampling and consistently show performance superior to the CMH test.

The GP framework is very flexible, which enables extensions utilizing for example LD over nearby alleles. As GP models can easily incorporate additional information on the data, we envisage that further promising combinations of the GP approach with evolutionary models will emerge. 

Supplementary Material
Supplementary Data
Acknowledgements
C.K. thanks the Institute of Pure and Applied Mathematics (IPAM) for a stay at the Genomics programme at which the idea of working on evolutionary time series data evolved. The computational results presented above have been performed using the computational resources provided by Aalto Science-IT project and partly using the Vienna Scientific Cluster (VSC).

Funding
The work was supported under the European ERASysBio+ initiative project ‘SYNERGY’ through the Academy of Finland [135311]. A.H. was also supported by the Academy of Finland [259440] and H.T. was supported by Alfred Kordelin Foundation. R.K. was supported by ERC (ArchAdapt). A.J. is member of the Vienna Graduate School of Population Genetics which is supported by a grant of the Austrian Science Fund (FWF) [W1225-B20]. 

Conflict of Interest: none declared.

