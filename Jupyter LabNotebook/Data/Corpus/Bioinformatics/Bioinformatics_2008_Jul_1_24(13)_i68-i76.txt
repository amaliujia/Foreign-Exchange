1 INTRODUCTION
The secondary structure adopted by an RNA molecule in vivo is a vital consideration in many bioinformatics analyses. In PCR primer design, stable secondary structures can obstruct proper binding of the primer to DNA (Dieffenbach et al., ); in RNA folding pathway studies, secondary structure forms the basic scaffold on which more complicated 3D structures organize (Brion and Westhof, ); and in computational non-coding RNA gene prediction, RNA secondary structural stability provides the characteristic signal for distinguishing real RNA sequence from non-functional transcripts (Eddy, ).

To date, the most powerful non-experimental methods for determining RNA secondary structure rely primarily on position-specific patterns of nucleotide covariation in multiple homologous RNA sequences. Specifically, enrichment for complementarity in pairs of columns from an RNA multiple alignment, especially when primary sequence is not conserved, provides strong evidence for potential base-pairings in the RNA's in vivo structure. A primary limitation of covariation analysis, however, is the difficulty of obtaining reliable sequence alignments for divergent RNA families. This shortcoming is especially relevant in the detection of ncRNA genes, as secondary structural constraints often exist even when primary sequence conservation is lacking (Torarinsson et al., ).

In this article, we describe RNA alignment and folding (RAF), a new algorithm for predicting RNA secondary structure from a collection of unaligned homologous RNA sequences. Algorithmically, RAF belongs to a category of RNA secondary structure prediction methods which simultaneously align and fold RNA sequences. By optimizing a pair of unaligned RNA sequences for both sequence homology and structural conservation concurrently, simultaneous alignment and folding approaches sidestep the usual problem of needing accurate sequence alignments before the folding is done. By exploiting sparsity in the set of likely base pairings and aligned nucleotides, RAF achieves O(L2) running time for sequences of length L, improving significantly upon the O(L4) running times of typical simultaneous folding and alignment approaches.

The main contribution of RAF, however, is its application of discriminative machine learning techniques for parameter estimation to the problem of simultaneous alignment and folding. Unlike previous methods, RAF's scoring model does not rely on ad hoc combinations of thermodynamic free energies for structural features (Mathews et al., ) with arbitrary alignment match and gap penalties (Hofacker et al., ), nor does RAF attempt the ambitious task of simultaneously modeling the evolutionary history of both sequences and structure (Knudsen and Hein, ). Instead, RAF defines a fixed set of basis features describing aspects of the alignment, RNA secondary structure, or both. RAF then poses the task of learning weights for these features as a convex optimization problem, giving rise to efficient algorithms with guaranteed convergence to optimality.

The concept of using discriminative methods for parameter estimation rather than relying solely on parameters compiled from experimental measurements originated with the CONTRAfold (Do et al., ) program, and later also became the basis of the CG (Andronescu et al., ) method. In a manner analogous to these two previous methods for single sequence secondary structure prediction, RAF demonstrates that automatic learning of parameters can also confer benefits to multiple sequence structure prediction accuracy.

2 METHODS
The RAF algorithm consists of four components: (1) a simple yet flexible objective function for pairwise alignment and folding of unaligned RNA sequences; (2) a fast Sankoff-style inference engine for maximizing this objective function via sparse dynamic programming; (3) a simple progressive strategy for extending the pairwise algorithm to handle multiple unaligned sequence inputs; and (4) a max-margin framework for automatically learning model parameters from training data. We describe each of these in turn.

2.1 The RAF scoring model
We begin our description of the algorithm by describing a scoring scheme for alignments and consensus foldings of two sequences. Let a and b be a pair of unaligned input RNA sequences. We refer to a candidate alignment and consensus secondary structure of a and b collectively as a parse. Formally, a parse y for a pair of sequences a and b is a set whose elements consist of base pairings (ai, aj) belonging to sequence a, base pairings (bk, bl) belonging to sequence b, and aligned positions (ai, bk) between a and b.

For a given parse y from the space of all valid parses ùí¥, RAF uses a simple scoring scheme which takes into account aligned positions and conserved base pairings. Specifically, RAF defines the score, Score(y;w), of such a parse y to be

where  and  are scoring terms for aligned positions and conserved base pairs, respectively, and where ‚Ñ¨(y) is the set of all conserved base pairings. In turn, RAF models each scoring term as a linear combination of arbitrary basis features ():

where w‚àà‚Ñùnaligned+nPaired=‚Ñùn is a vector of scoring parameters.

2.2 Fast pairwise alignment and folding
Given the scoring scheme described in the previous section, the problem of simultaneous alignment and folding reduces to the optimization problem,

In principle, the solution to () follows immediately from the original dynamic programming algorithm for simultaneous alignment and folding presented by Sankoff (). Sankoff's algorithm, however, has an O(L3K) time complexity and O(L2K) space complexity for K sequences of length L, rendering it impractical for all but the smallest multiple folding problems. Therefore, most programs for RNA simultaneous alignment and folding use heuristics to reduce time and memory requirements while minimally compromising alignment and structure-prediction quality. Some heuristics used in previous programs have included incorporating structural information into a single alignment scoring matrix (Dalli et al., ), disallowing multi-branch loops (Gorodkin et al., ), and precomputing potential conserved helices prior to alignment (Tabei et al., ; Touzet and Perriquet, ).

The most popular heuristics, however, involve reduction of the portion of the dynamic programming matrices (which we call the DP region) that must be computed. For example, some methods restrict the DP region to a strip of fixed width about the diagonal (Hofacker et al., ; Mathews and Turner, ) or about an initial alignment path (Kiryu et al., ). Other methods rely on external single-sequence folding and probabilistic alignment programs to generate base pairing probability matrices (Torarinsson et al., ; Will et al., ) or alignment match posterior probability matrices (Kiryu et al., ), and then exploit the sparsity of these matrices in order to reduce the amount of computation required.

The RAF algorithm adopts the last of these strategies. Namely, RAF uses a single-sequence RNA secondary structure prediction program CONTRAfold; Do et al., ) and a pairwise RNA sequence alignment program (CONTRAlign; Do et al., ), respectively, to construct a constraint set ùíû of allowed base pairs and aligned positions in a and b. Given a constraint set ùíû, RAF then replaces () with the reduced inference problem,

where ùí¥ùíû={y‚ààùí¥:y‚äÜùíû} is the space of valid parses, restricted to those which contain only base pairings and alignment matches from the constraint set ùíû ().
Sparsity patterns in posterior probability matrices. Panels (a) and (b) illustrate the pairwise pairing posterior probabilities for two different sequences (such as generated by a single-sequence probabilistic or partition function‚Äìbased RNA folding program). Panel (c) shows the alignment match probabilities for these sequences (such as generated by a probabilistic HMM). In each panel, the darkness of each square represents the posterior confidence in the corresponding base pairing or alignment match. While the single sequence folder or the pairwise sequence aligner may not be able to identify the single correct folding or alignment, respectively, the set of likely candidate base pairings and matched positions, nonetheless, is extremely sparse.




To obtain the set of allowed base pairings, RAF uses the implementation of McCaskill's algorithm (McCaskill, ) from CONTRAfold in order to compute the posterior probability of each possible base pairing in sequence a, and similarly for sequence b. All base pairs with posterior probability at least …õpaired are then retained. Similarly, to determine the set of allowed aligned positions, RAF retains those matches whose posterior probability, according to a version of the CONTRAlign program adapted for RNAs, is at least …õaligned. If these cutoffs …õaligned and …õpaired are chosen to be too low, then the reduction of the dynamic programming space achieved for ùí¥ùíû will not be significant. Conversely, a higher cutoff could also degrade performance by excluding portions of the DP matrix which actually correspond to the true parse of the input sequences. A similar approach for pruning the space of candidate alignments and folds via fold and alignment envelopes was implemented in the Stemloc (Holmes, ) program. A number of other programs exploit either base-pairing sparsity (Torarinsson et al., ; Will et al., ) or alignment sparsity (Dowell and Eddy, ; Harmanci et al., ; Kiryu et al., ) separately.

Assuming O(c) and O(d) bounds on the number of candidate base pairing and alignment partners, respectively, per position of both sequences, we show that the time complexity of the RAF algorithm scales quadratically in the length of the sequences, while the space complexity scales linearly (). A comparison table of asymptotic time and space complexity of a number of modern RNA simultaneous folding and alignment approaches is shown in . In practice, we find that RAF's scaling reflects the theoretical bounds, achieving running times often an order of magnitude faster than current simultaneous alignment and folding methods.
Comparison of computational complexity of RNA simultaneous folding and alignment algorithms

Algorithm	Time complexity	Space complexity	
Sankoff	O(L6)	O(L4)	
FOLDALIGN	O(L4)	O(L4)	
LocARNA	O(c2L4)	O(c2L2)	
Murlet	O(d2L2+d3L3/Œ∫6)	O(d2L2)	
RAF	O(min(c,d)¬∑cd2L2)	O(min(c,d)¬∑cdL)	
Here, L denotes the sequence length, c is the number of candidate base pairs per position, d is the number of candidate alignment matches per position and Œ∫ is the minimum allowed distance between adjacent helices.



2.3 Extension to multiple alignment
Using the RAF pairwise alignment subroutine, we can also address the problem of aligning two alignments. Let S and T be two sets of sequences that we wish to align; furthermore, we denote their corresponding alignments as A and B.

To align a pair of alignments, we first define new basis features  and  to simply be the average over all pairs of sequences s‚ààS and t‚ààT of the basis features for aligning s and t, remapped to the coordinates of the alignments A and B. Second, we define the new constraint set ùíû for aligning the two alignments to be the union over all pairs of sequences s‚ààS and t‚ààT of the constraint sets for each pair, again remapped to the alignment coordinates. Finally, using these new features and our new constraint set, we simply call the existing RAF subroutine for fast-pairwise alignment and folding.

Using this new subroutine for aligning alignments, we can then perform multiple alignment in RAF using a standard progressive strategy (Feng and Doolittle, ). Specifically, we cluster the sequences with a UPGMA (Sneath and Sokal, ) tree-building procedure, using the expected accuracy similarity measure (Do et al., ). Finally, we perform progressive alignment by aligning subgroups of sequences according to the tree.

2.4 A max-margin framework
Given a set of training examples, , the parameter estimation problem is the task of identifying a vector of weights w=(w1,w2,‚Ä¶,wn)‚àà‚Ñùn for which the RAF inference algorithm, as described in the previous section, will yield accurate alignments and consensus structures. In this section, we present a max-margin framework for parameter estimation in RAF.

2.4.1 Formulation
In the max-margin framework, our goal is to obtain a parameter vector w for which running the RAF inference algorithm will generate accurate alignments and consensus structures. Clearly, this goal is met if for each training example (a(i),b(i),y(i)) from our training set S,

In such a case, we would be guaranteed that the maximum of () is attained for y*=y(i) (provided the true parse y(i) belongs to ), and hence our inference procedure would necessarily return the correct alignment and consensus folding. This intuition is captured in the following convex optimization problem:

Here, C is a regularization constant, and Œî(y(i),y‚Ä≤) is a non-negative distance measure between pair of parses, conventionally referred to as the loss function, which takes value 0 if and only if its two arguments are equal ().

The inequality constraints play the role of ()‚Äîthey try to ensure that the training output y(i) scores higher than any alternative incorrect parse y‚Ä≤ by some positive amount Œî(y(i),y‚Ä≤). In cases where this condition is not achieved, the objective function incurs a penalty of Œæi. Finally, the regularization term (¬Ω)C‚Äñw‚Äñ2 is a penalty used to prevent overfitting.

2.4.2 The loss function
The loss function Œî(y(i),y‚Ä≤) in () plays two significant roles. Technically, the loss function establishes an appropriate scale for the parameters of the problem and prevents the trivial solution, w=0. Intuitively, however, the loss function also helps to make the max-margin optimization robust. By choosing a loss function that takes large positive values for incorrect candidate outputs y‚Ä≤ that differ from the true output y(i) in a very critical way, but that takes small positive values for incorrect candidate outputs y‚Ä≤ whose errors are more forgivable, the loss function allows the user to implement a notion of ‚Äòcost‚Äô for different types of mistakes in the max-margin model.

For RAF, we defined the loss function by restricting our attention to four types of parsing errors: (1) false positive base-pairings ((ai, aj)‚àày‚Ä≤ ‚àñ y(i), or similarly in sequence b), (2) false negative base-pairings ((ai, aj)‚ààyi ‚àñ y‚Ä≤, or similarly in sequence b), (3) false positive aligned matches ((ai, bk)‚àày‚Äô ‚àñ y(i)) and (4) false negative aligned matches ((ai, bk)‚àày(i) ‚àñ y‚Ä≤). Then, we set

The numbers Œ≥FN paired, Œ≥FP paired, Œ≥FN aligned and Œ≥FP aligned are hyperparameters, chosen by the user prior to training the RAF algorithm, which allow the user to express her preference for models with either high sensitivity or high specificity for base-pairing positions and aligned nucleotides.

2.4.3 Optimization algorithm
At first glance, the constrained optimization problem stated in () appears to be a standard convex quadratic program and hence solvable using off-the-shelf packages for convex programming. In reality, for each training example, the optimization problem has an exponential number of inequalities, one corresponding to each possible candidate parse y‚Ä≤ of the input sequences! Despite our use of constraints sets to reduce the set of allowed candidate outputs, in most cases, this space is still too large to enumerate.

One approach to deal with this problem is an iterative algorithm known as constraint generation (or column generation), as used in the program CG (Andronescu et al., ). In this approach, the parameter vector wt at each time t is the solution to a reduced version of () in which only a small subset of the constraints are retained. Next, one checks if wt violates any of the constraints of the original full optimization problem by more than an prescribed tolerance of …õ. If so, the worst violated constraint is added to the current set of constraints to form a new reduced optimization problem, whose solution, in turn, gives the next iterate wt+1. If not, the optimization algorithm terminates. Each of the optimization problems in the sequence requires a quadratic programming solver.

Here, we take a simpler approach based on the recent SVM training algorithm of (Shalev-Shwartz and Singer, ) and Shalev-Shwartz et al., (). Omitting details, we begin by converting () into an equivalent unconstrained problem: namely, minimize (with respect to w‚àà‚Ñùn),

Next, we use strong duality from optimization theory in order to derive an upper bound B on the norm of the optimal solution of our unconstrained problem (). Finally, we actually run the optimization procedure by applying the simple update rule,

starting from w1=0. Here, gt‚àà‚àÇf(wt) is any subgradient of the objective function f(w) evaluated at w=wt, and the operator Œ†B[¬∑] projects a vector onto an origin-centered ball of radius B (i.e. Œ†B[v]=(B/‚Äñv‚Äñ)v if ‚Äñv‚Äñ&gt;B and Œ†B[v]=v otherwise). Intuitively, the algorithm works much like a standard gradient descent procedure adapted for non-differentiable objective functions, but with the added twist that the projection operation ensures that the weight vector iterates stay with a region of the parameter space where the optimum is known to exist.

Given an existing routine for computing subgradients of the unconstrained objective, this algorithm can be implemented in a few lines of code with no complicated numerical optimization software. As shown by Singer and Shalev-Shwartz, the algorithm is also quite efficient, requiring only √ï(m/C…õ) iterations to achieve …õ accuracy on a training set of m examples. An online variant of the algorithm, in which the subgradients gt in each step are computed based only on a randomly sampled subset of the training data (e.g. a single example), achieves an √ï(1/C…õ) expected running time, independent of m, the size of the training set.

2.4.4 Subgradient computation
Finally, we show how to compute a subgradient gt‚àà‚àÇf(wt). In order to simplify notation, define an n-dimensional vector Œ¶(y) whose pth component is

from which it follows that Score(y;w)=wTŒ¶(y). We can apply the usual rules for computing subgradients see, e.g. Bertsekas et al., ) to obtain

where  is simply any y‚Ä≤ which attains the maximum in the ith term of the summation in (), for w=wt. Each ‚Äòloss-augmented‚Äô maximization, in turn, is easily performed by modifying the original RAF inference procedure to incorporate an appropriately defined additional scoring matrix, œÜ0(i, j; k, l), with fixed weight w0=1.

3 RESULTS
To evaluate the performance of RAF on real data, we collected training and testing data from a variety of sources. In particular, for training, we obtained Rfam 8.1 (Griffiths-Jones et al., ), a database of alignments and covariance models for RNA families along with annotated secondary structures where available. For testing, we obtained BRAliBASE II (Gardner et al., ), a benchmark set for RNA alignment programs. We also obtained a testing set of RNA families used by the authors of the recent program, MASTR (Lindgreen et al., ).

An important concern in the validation of RNA alignment programs is the confounding factor that unless cross-validation is properly performed, the performance that one sees on any given validation set is not likely to be a reliable judge of the program's performance on future data. Even in cases where the training and evaluation tests are disjoint but still contain sequences from the same RNA family, evaluation can still give misleading results, because the weights learned for loop lengths and composition will be biased toward specific properties of that RNA family.

To be absolutely sure of no contamination between training and testing data, we preprocessed our Rfam training set of alignments and consensus structures (October 2007 version, 607 families) by excluding all families for which either of the two testing databases contained an example from that family. We then also removed all families for which only automatically predicted consensus structures were known, leaving a total of 154 families. Finally, we generated a training set ùíØ1 of up to 10 randomly sampled pairwise alignments with consensus structures from each remaining family (1361 pairwise alignments in total), a training set ùíØ2, of up to 10 randomly sampled sequences with structures from each family (1179 sequences in total), and a training set ùíØ3, containing one randomly sampled five-way multiple alignment from each family (118 multiple alignments in total).

RAF uses two external programs, CONTRAlign (Do et al., ) and CONTRAfold (Do et al., ), to compute alignment match and base-pairing posterior probabilities, respectively. To ensure proper cross-validation, CONTRAlign was retrained from scratch using ùíØ1, and CONTRAfold was retrained using ùíØ2. Finally, the RAF algorithm itself was trained using all pairwise projections of each multiple alignment of ùíØ3. Our strict cross-validation procedure significantly reduces both the size and coverage of the training sets used for CONTRAlign and CONTRAfold, and thus places RAF at a significant disadvantage in the comparisons shown here. Nonetheless, as shown in the following sections, RAF performs well, indicating its ability to generalize for sequences not present in the training set.

3.1 Alignment and base-pairing constraints
To observe the effects of different cutoffs …õaligned and …õpaired, we computed the proportions of reference base pairings and reference aligned matches recovered for varying cutoff constraints. In addition, we also computed the sparsity ratio (i.e. the maximum number of pairing partners or matching partners for any nucleotide, averaged over the entire training set) for each cutoff. A plot of these two values for training set ùíØ3 is shown in . As seen in the figure, nearly complete coverage of base pairings and alignment matches can be retained when each sparsity factor is roughly 10.
Trade-off between sparsity factor and proportion of reference base-pairings or aligned matches covered when varying the cutoffs …õpaired and …õaligned. This graph was made using training set ùíØ3.




3.2 Evaluation metrics
To evaluate the quality of the resulting alignments, we used five different scoring measures:
(1) the standard sum-of-pairs (SP) score (Thompson et al., ), which computes the proportion of matches in a reference alignment which are present in the predicted alignment,

(2) sensitivity (Sens), the proportion of base pairings in a reference parse which are recovered in the predicted parse,

(3) specificity or positive-predictive value (PPV), the proportion of base pairings in a predicted parse which are also present in the reference parse, and

(4) the Matthews correlation coefficient (MCC) (Matthews, ), which we approximate as , following Gorodkin et al., ().




3.3 Comparison of accuracy
In our first accuracy assessment, we evaluated RAF as well as a number of other current RNA secondary structure prediction programs using the BRAliBASE II dataset. In particular, the first dataset from BRAliBASE II contains collections of 100 five-sequence subalignments, sampled from five specific Rfam families (5S rRNA, group II intron, SRP, tRNA and U5). For each of these alignments, we ran a number of current multiple-sequence RNA secondary structure prediction programs, including Murlet v0.1.1 (Kiryu et al., ), LocARNA v1.2.2a (Will et al., ), and RNA Sampler v1.3 (Xu et al., ). Wherever any of these programs required access to external pairing-posterior probabilities, we used ViennaRNA v1.7 (Hofacker et al., ). The results of the comparison are shown in .
Performance comparison on BRAliBASE II datasets. The best number in each column is marked in bold

Dataset	Program	Time (s)	SP	Sens	PPV	MCC	
5S rRNA	Murlet	687	0.94	0.70	0.70	0.70	
	LocARNA	812	0.93	0.55	0.60	0.57	
	RNA Sampler	2361	0.90	0.55	0.64	0.59	
	RAF	87	0.95	0.66	0.66	0.66	
group II intron	Murlet	962	0.78	0.75	0.76	0.75	
	LocARNA	250	0.74	0.79	0.65	0.72	
	RNA Sampler	1626	0.72	0.77	0.65	0.71	
	RAF	48	0.78	0.83	0.65	0.73	
SRP	Murlet	20548	0.88	0.75	0.78	0.76	
	LocARNA	22467	0.85	0.66	0.70	0.68	
	RAF	1290	0.87	0.72	0.71	0.70	
tRNA	Murlet	525	0.93	0.86	0.90	0.88	
	LocARNA	246	0.95	0.86	0.90	0.88	
	RNA Sampler	763	0.92	0.93	0.91	0.92	
	RAF	52	0.94	0.81	0.85	0.83	
U5	Murlet	1772	0.84	0.69	0.75	0.72	
	LocARNA	549	0.80	0.56	0.61	0.58	
	RNA Sampler	4084	0.77	0.75	0.70	0.72	
	RAF	99	0.82	0.83	0.79	0.81	


As seen from the table, on the BRAliBASE II benchmark, RAF attains comparable accuracy to the other methods, achieving either the best or second-best overall accuracy according to MCC on four out of the five datasets. The running time of the method, however, is dramatically faster than the other algorithms, often taking an order of magnitude less time than many of the other programs.

We also obtained the dataset used in the benchmarking of the MASTR RNA secondary structure prediction program. For a number of different programs, pre-generated predictions for each input file are available for download on the MASTR website. In addition to scoring these pre-generated predictions, we also generated and scored predictions using Murlet and RAF. The results are shown in . In this benchmark set, RAF obtains the highest overall MCC.
Performance comparison on MASTR benchmarking sets. The best number in each column is marked in bold.

Program	SP	Sens	PPV	MCC	
CLUSTAL W+Alifold	0.81	0.57	0.73	0.65	
FoldalignM	0.78	0.38	0.81	0.55	
LocARNA	0.75	0.41	0.77	0.56	
MASTR	0.84	0.64	0.73	0.68	
Murlet	0.89	0.62	0.78	0.70	
RNAforester	0.53	0.55	0.55	0.55	
RNA Sampler	0.82	0.65	0.70	0.67	
RAF	0.88	0.68	0.77	0.72	



We emphasize, however, that benchmarking results such as these should be taken with a grain of salt; both the BRAliBASE II and MASTR benchmarking sets are extremely restricted in their coverage of the space of RNA families, choosing to focus on a few individual RNA families only. As a result, methods carefully tuned to the benchmarks may perform less well on diverse RNA families not found in either of these benchmarks. By using cross-validation, we improve the chances that RAF's validation results really do indicate reliable out-of-sample performance.

We also note that the performance of RAF on particular RNA families is often closely related to the accuracy of the underlying alignment and single-sequence models used to derive folding and alignment constraints. Because the tools involved in the RAF pipeline all rely on automatic parameter learning, RAF allows the possibility of learning custom parameter sets well-suited for predictions on particular RNA families.

4 DISCUSSION
We presented RAF, a new tool for simultaneous folding and alignment of RNA sequences which exploits sparsity in base pairing and alignment probability matrices and max-margin training in order to achieve faster running times and higher accuracy than previous tools.

Besides its speed, one principal advantage of the RAF meth-odology is its use of a flexible scoring function for combining an arbitrary set of functions into a coherent objective function for alignment scoring. The ability to introduce new basis scoring functions into the RAF scoring model means that there remains a rich space of possible features to explore.

In addition, the use of the max-margin framework to identify relevant linear combinations of scoring functions has other promising potential applications. For example, Wallace et al. () recently introduced M-Coffee, a meta-algorithm for protein sequence alignment, which combines the results of several different protein sequence alignment programs using the T-Coffee framework. The difficulty of identifying appropriate weights for the various programs used in the M-Coffee scoring scheme (i.e. some heuristically derived tree-based weights the authors tried did not give a significant improvement in accuracy over flat weights), led the authors to rely on a uniform weight model, treating programs known to be more accurate on equal footing with less accurate aligners. The max-margin framework developed in this paper obviates the need for heuristically-derived weights altogether.

1We say that a parse y of inputs a and b is valid provided that (1) each nucleotide of a and b base pairs with at most one other nucleotide in the same sequence; (2) each nucleotide aligns with at most one nucleotide in the opposite sequence; (3) neither sequence contains pseudo-knotted base pairings; (4) the alignment of the two sequences does not contain rearrangements or repeats; and (5) all base pairings are conserved.

2The original CONTRAlign program was designed for protein sequences. We adapted this for RNAs by removing all protein-specific features (e.g. hydrophobicity), modifying the underlying alphabet (A, C, G and U) and simply retraining on the appropriate training set.

3We note that the method described here bears some relation to the ‚Äòcandidate list‚Äô algorithm of Wexler et al. (), which maintains sparse lists of potential bifurcation points for single sequence folding. By showing that the number of relevant bifurcation points has a negligible dependence on sequence length, the authors provide an effectively quadratic time algorithm for single-sequence folding. Here, our algorithm also relies on sparsity of bifurcation point candidates when dealing with pairwise alignment and folding, but unlike in the previous algorithm, the candidates are provided explicitly via the constraint set ùíû.

4Note that our notation hides the dependencies of the Score function on each of the input sequences a(i) and b(i), and similarly for the unconstrained and constrained space of parses, ùí¥(i) and .

5By default, we used C=1. We found that when running the online Pegasos optimization algorithm () for a fixed number of iterations, the resulting generalization performance for RAF is relatively insensitive to the value of C used, provided that C is not too large.

6By default, we used Œ≥FN paired=10, and Œ≥FP paired=Œ≥FN aligned=Œ≥FP aligned=1 in order to emphasize prediction of correct base pairings.

7In practice, we found that using cutoffs of …õaligned‚àº0.01 and …õpaired ‚àº 0.002 gave a good trade-off between speed and accuracy of our algorithm when using CONTRAlign and CONTRAfold; these cutoffs correspond roughly to average sparsity factors of ‚àº10 each, respectively.

8That is,  whenever  for some j1&lt;j&lt;j2, or  for some l1&lt;l&lt;l2.

9Note that in these bounds, we assume an O(c) bound on the number of base-pairing partners per position, and an O(d) bound on the number of aligning partners per position. A weaker condition would be to assume an O(cL) bound on the total number of candidate base-pairing partners for sequences a and b and similarly, an O(dL) bound on the total number of candidate aligned positions; under these conditions, we obtain a worst-case space complexity of O(min(c,d)2 L2) and a worst case time complexity of O(min(c,d)2dL3).

ACKNOWLEDGEMENTS
C.B.D. was supported by an NSF Graduate Research Fellowship. C.S.F. was supported by an A*STAR National Science Scholarship. This material is based in part upon work supported by the NSF under grant number EF-0312459.

Conflict of Interest: none declared.

APPENDIX
A.1 RAF features
The features used by the RAF program, as evaluated in this article, consist of alignment features,  and pairing features, . Specifically, the alignment features, œÜaligned(i, k)‚àà‚Ñù4 for a candidate alignment match (ai, bk) are

The pairing features, œÜpaired(i, j; k, l)‚àà‚Ñù4 for a conserved base pairing ‚å©(ai, aj), (bk, bl)‚å™ are given by œÜpaired(i, j; k, l)=œÜpaired(ai, aj)+œÜpaired(bk, bl). In turn, œÜpaired(ai, aj)‚àà‚Ñù4 is given by

and similarly for œÜpaired(bk, bl). Thus, the model contains a total of eight features whose weights must be learned. Here, the posterior probabilities for aligned positions and base-pairing positions are computed using the CONTRAlign (Do et al., ) and CONTRAfold (Do et al., ) programs, respectively.

B.1 The RAF inference engine
In the section, we describe the RAF inference engine for fast approximate simultaneous alignment and consensus folding for pairs of sequences. In particular, we first present some exact recurrences for alignment and folding, and then use restrictions on the set of allowed base pairings and aligned positions to achieve an improvement in computational complexity.

B.1.1 Recurrences
First, we describe a straightforward O(L6) dynamic programming recurrence for computing the optimal simultaneous alignment and consensus fold for a pair of sequences a and b.

To compute the optimal parse of a and b, we construct 2 four-dimensional matrices, S and D. Here, Si, j; k, l denotes the optimal score for aligning and folding ai+1ai+2‚Ä¶aj with bk+1bk+2‚Ä¶bl. Furthermore, Di, j; k, l denotes the optimal score for aligning and folding these same substrings, subject to the additional constraint that the outermost positions (ai+1,aj) and (bk+1,bl) form conserved base pairs.

For 0‚â§i‚â§j‚â§|a| and 0‚â§k‚â§l‚â§|b|, we have

and for 0‚â§i&lt;i+2‚â§j‚â§|a| and 0‚â§k&lt;k+2‚â§l‚â§|b|,

Here, recurrence (B1) takes the form of a standard Needleman-Wunsch procedure for aligning the substring ai+1ai+2‚Ä¶ aj with bk+1bk+2‚Ä¶bl, with an extra case to handle bifurcations in the base-pairing structure of the RNAs. At the end of the recurrence, S0,|a|;0,|b| gives the score of the optimal alignment and consensus fold of the input sequences a and b. By using traceback pointers in the standard way, the optimal parse can be recovered easily once the recurrence has been evaluated.

In the next section, we explore how these recurrences may be sped up considerably if a constraint set ùíû of allowed base pairings and aligned positions is known ahead of time. For complexity analysis, we assume O(c) and O(d) bounds on the number of candidate base pairing and alignment partners per sequence position, respectively.

B.1.2 Exploiting base-pairing sparsity
LocARNA (Will et al., ) was the first program for simultaneous alignment and folding of RNA to take advantage of base pairing sparsity in a manner that significantly improved in both running time and memory usage. In this section, we recount the innovations of LocARNA as they are applied in RAF. In the next section, we extend these ideas to also account for alignment sparsity.

First, observe that since all parses in ùí¥ùíû contain only conserved base pairings, the evaluation of () may be restricted to only those Di, j; k, l cells for which both (ai+1,aj)‚ààùíû and (bk+1,bl)‚ààùíû. Similarly, the inner loop for considering bifurcations in () may also be restricted to only those j‚Ä≤ and l‚Ä≤ for which both (aj‚Ä≤+1,aj)‚ààùíû and (bl‚Ä≤+1,bl)‚ààùíû. Since the bottleneck in the dynamic programming complexity is the number of executions of the innermost loop in (), it follows that restricting the considered bifurcations in the manner described above yields an O(c2L4) running time; in particular, for each i and k, computing all values of Si,‚Ä¢;k,‚Ä¢ takes O(c2L2) time as each entry of the D matrix is touched at most once. This optimization was originally implemented as part of the LocARNA (Will et al., ) and FoldAlignM (Torarinsson et al., ) algorithms.

Second, consider the task of computing all entries in the D matrix. From (B2), we see that the values Di,‚Ä¢;k,‚Ä¢ depend only on Si+1,‚Ä¢;k+1,‚Ä¢. Similarly, from (), the values Si+1,‚Ä¢;k+1,‚Ä¢ depend only on Dj‚Ä≤,j;l‚Ä≤,l for j‚Ä≤‚â•i+1 and l‚Ä≤‚â•k+1. Thus, ordering computations in the following way allows the recurrences to be evaluated in a single pass:

Furthermore, since Si+1,‚Ä¢;k+1,‚Ä¢ is only needed while computing Di,‚Ä¢;k,‚Ä¢ (but not for any later values of i and k), we need only to retain one Si+1,‚Ä¢;k+1,‚Ä¢ matrix in memory at any given time while computing the D matrix. This observation was originally incorporated in the LocARNA program of Will et al., ().

Finally, observe that once the D matrix has been computed, the score S0,|a|;0,|b| of the optimal parse is easily obtainable in O(c2L2) time by recomputing S0,‚Ä¢;0,‚Ä¢. Likewise, computing the full traceback requires at most O(c2L3) time, negligible relative to the cost of computing the D matrix itself. Thus, we obtain an overall O(c2L4) time complexity with O(c2L2) space complexity (for storing the D matrix).

B.1.3 Exploiting alignment sparsity
To exploit sparsity in the set of allowed aligned positions in ùíû, we again use the strategy of limiting the DP region. We accomplish this by first considering the simpler problem of computing the reduced DP region ùíú (known as the alignment envelope) for pairwise sequence alignment without folding scores. Using ùíú, we then define a reduced DP region for our original alignment and folding task.

For the first step, consider the following restatement of recurrence () using the notation , where we have omitted the case involving bifurcations/base pairing:

As before,  represents the optimal score of aligning a1a2‚Ä¶aj to b1 b2 ‚Ä¶ bl. Here, our goal is to find ùíú, the minimal set of cells containing no holes, such that for every parse y‚ààùí¥ùíû, there exists some DP path through ùíú corresponding to an alignment with the same set of aligned positions. Under the assumption that ùíú contains no holes, we can represent ùíú by keeping track of its boundaries: for each j‚àà{0,1,‚Ä¶,|a|}, let ‚å©{ùíú}.First[j], ùíú.Last[j]‚å™ denote the first and last positions l‚àà{0,1,‚Ä¶,|b|} such that .

We compute these boundaries in linear time using the following procedure. First, we adjust the boundaries to include  and  for each candidate aligning pair (aj,bl)‚ààùíû. In addition, we also include the corners  and  in ùíú. Finally, we force the boundaries of ùíú to satisfy the monotonicity conditions

in such a way that guarantees all DP cells  are accessible via some DP path from  to .

For the second step, we define the reduced DP region for our original simultaneous alignment and folding recurrences as the set ‚Ñõ of all positions Si, j; k, l such that  and . To use this reduced DP region ‚Ñõ, then, we simply force Si, j; k, l=‚àí‚àû for all Si, j; k, l ‚àâ ‚Ñõ. Under this restriction, we can reduce the amount of computation performed in the recurrence () by iterating only over cells Si, j; k, l‚àà‚Ñõ, and similarly, restricting the evaluation of the D matrix in () to only those cells Di, j; k, l for which Si+1,j‚àí1;k+1,l‚àí1‚àà‚Ñõ. To ensure that each allowed parse belongs to ùí¥ùíû, we could penalize any base pairing or aligned position not in ùíû by ‚àí‚àû. In practice, we instead augment ùíû to include all aligned matches allowed by ‚Ñõ, since this can be done at no increase in computational complexity.

To analyze the new computational complexity of the algorithm, we begin by bounding the size of D matrix in two different ways. First, for each of the O(cL) base pairs (ai, aj)‚ààùíû, there are O(d) aligning partners for ai and O(d) aligning partners for aj, giving a total size of O(cd2L). Alternatively, for each of the O(dL) aligning pairs (ai, bk)‚ààùíû, there are O(c) base-pairing partners for ai and O(c) base-pairing partners for bk, giving a total size of O(c2dL). Thus, the size of the D matrix is O(min(c,d)¬∑cdL).

As in Section B.1.2, the space complexity of the algorithm is dominated by cost of storing the D matrix, and hence, is O(min(c,d)¬∑cdL). Similarly, the time complexity can be estimated as the number of evaluations of the innermost loop in the bifurcation case of (). Since the innermost loop touches each entry of the D matrix at most once for each i and k, and since there are O(dL) choices of (ai, bk)‚ààùíú, it follows that the time complexity of the algorithm is O(min(c,d)¬∑cd2L2).

C.1 Norm bound
In this section, we derive a bound on the maximum norm of the optimal parameter vector w* for (). From standard arguments (see, e.g. Taskar et al., ), the dual optimization problem is

where

By strong duality, for any solutions (w*,Œæ*) and Œ±* of the primal and dual optimization problems, respectively, the values of the primal and dual objectives must be equal, i.e.,

Now, suppose that Di‚àà‚Ñù for i=1,‚Ä¶,m satisfy

In the case of the RAF loss function, for example, we can use

Then the KKT optimality condition w*=w(Œ±*), the primal constraint that  for i=1,‚Ä¶,m, and () imply that

Therefore, .‚ÄÉ‚ñ™

