1 INTRODUCTION
Macromolecules (proteins, nucleic acids, lipids and carbohydrates) can be rapidly visualized in cells and tissue via staining with antibodies and/or special stains, followed by bright field color imaging. However, the quantitative analysis of such images is often hindered by variations in sample preparations, the limited dynamic range of color cameras, and the fact that image formation is not at a specific excitation and emission frequency, which is the hallmark of fluorescence microscopy. Through consistent sample preparation, fixation and imaging, we suggest that the signals associated with a macromolecule can be decomposed in the color space, and can render a scoring value on a cell-by-cell basis. Following this protocol, protein, lipid and DNA complexes are visualized with antibodies and special stains, and then imaged with a color CCD camera attached to a microscope.The key contributions of this article are in: (i) formulating the color decomposition as a global optimization problem, (ii) representing the signal complexes, associated with protein localization, with multiple prior models and (iii) applying the proposed method to the analysis of an end point on a cell-by-cell basis. In this context, global optimization is realized through the graph cut method, multiple prior models are specified through user initialization, and signal analysis, on a cell-by-cell basis, is established through a best effort in establishing cellular boundaries. The logical flow of these various computational steps is shown in , whereby the user first specifies regions associated with positive staining in an image, the nuclear regions are then automatically detected as a dark elliptic region (Yang and Parvin, ), and are later further refined following color decomposition. The morphology and position of nuclear features allow the region-based tessellation of the image, and the subsequent scoring of the signaling complex on a cell-by-cell basis.
Computational steps in quantifying stained samples: in a single image, the user initializes the stained region associated with a signaling macromolecule. Learned parameters are subsequently used for the rest of the dataset.



We applied our method to fibroblasts grown from histologically normal breast tissue biopsies obtained from women from two distinct populations. The biopsies were digested in solution and the fibroblasts purified and grown in vitro. These fibroblasts were then grown under conditions that support adipocyte differentiation for 5‚Äì7 days before being fixed and stained with hematoxylin and Oil Red O, which stain DNA and lipids, respectively. Although hematoxylin and Oil Red O visualize nuclei in blue and lipids in red, respectively, there is still some overlap in the color space.

This article has been organized as follows:  reviews previous research in the area of color decomposition from histologically stained tissues;  demonstrates the effectiveness of our method when stains are co-localized;  provides the details of our method;  summarizes the results of our method and the application of our method to a large dataset and  concludes the article.

2 REVIEW OF PREVIOUS WORK
Current practices in the quantitative assessment of histological samples fall into two categories: standard imaging microscopes and specialized systems. Standard imaging microscopes use a color CCD camera and non-coherent light. The images are scored with non-negative matrix factorization (NMF) (Rabinovich et al., ), which models each dye as an additive factor in the color space, where the resulting image is deconvolved by color unmixing. This method is quite powerful; however, it ignores spatial relationships between nearby pixels, is sensitive to the initial condition, and may not be able to deconvolve dyes that have too much overlap in the color space. In addition to its successful application to spatial data (Lee and Seung, ), NMF has also been used in the analysis of gene expression data to reveal an intuitive meaning in terms of a small subset of metagenes (Gao and Church, ). Specialized systems (Papadakis et al., ) leverage tunable illumination, fast hyperspectral imaging and monochromatic CCD cameras. The primary advantage of such an optical band pass is in its ability to resolve different stains whose spectra overlap when using the standard system. However, it still requires additional processing, from a stack of band pass images, for cell-by-cell analysis.

Our approach relies on a standard microscope with a color CCD camera (e.g. bright field imaging) to demonstrate that the proposed method: (i) improves color decomposition, (ii) has better noise immunity and (iii) has superior performance.

3 APPROACH
In our computational protocol, nuclear segmentation and color decomposition proceed in parallel. Although nuclear segmentation is not the focus of our article, it is an important step in constructing a system, and a method is outlined here for completeness. However, this method can be replaced with other nuclear segmentation methods. In this system, segmentation of nuclear regions is realized by detecting elliptic features (Yang and Parvin, ) corresponding to potential dark regions. These regions are further filtered for their intensities and shape features. At the same time, the amount of staining is characterized by a graph cut algorithm through color decomposition. In rare cases, samples may be locally corrupted with foreign materials leading to small dark patches that resemble the nuclear signature. These dark patches are further filtered following color decomposition to eliminate false association to the nuclear stain. Finally, staining is associated with each nucleus through region-based tessellation.

3.1 Nuclear segmentation
Examples of treated and positive control images are shown in  and , respectively. The nuclear intensities, in the color space, are quite similar to the surrounding background, thus hindering the use of traditional delineation based on the color features. However, by converting the color image into a gray-level image, distinct intensity features of the nuclear region are accentuated through a decrease in the intensity magnitude. This decrease in the intensity feature has a trough that can be detected as a dark elliptic feature. Conversion to a gray-level image is as follows:

where R, G and B are the red, green and blue channels, respectively, of the original color image, and Œ±=0.21, Œ≤=0.72 and Œ≥ = 0.07. Unlike immunofluorescence labeling, thresholding is inadequate for this class of images. Our approach is to detect elliptic features (Yang and Parvin, ) for the delineation of dark regions in the image. Let the linear scale-space representation of the original image I0(x, y) at scale œÉ be given by:

where G(x, y; œÉ) is the Gaussian kernel with a SD of œÉ. For simplicity I(x, y; œÉ) is also denoted as I(x, y) below. At each point (x, y), the iso-intensity Contour is defined by:

where (Œîx, Œîy) is the displacement vector. Expanding and truncating the above equation using Taylor's series, we have the following estimation:

where

is the Hessian matrix of I(x, y). The entire image domain is divided by Equation () into two parts:

and

or locally

and

If H(x, y) is positive definite, then the region defined by Equation () is locally convex. Similarly, if H(x, y) is negative definite, then the region defined by Equation () is locally convex. To determine whether H(x, y) &gt; 0 or H(x, y) &lt; 0, we analyze this feature in both cases: (I) H(x, y) &gt; 0. Then Ixx &gt; 0, Iyy &gt; 0, and hence Ixx + Iyy &gt; 0, and positive Laplacian means that (x, y) is a ‚Äòdark point‚Äô, i.e. a point that is darker than its neighbors; and (II) H(x, y) &lt; 0. Then Ixx &lt; 0, Iyy &lt; 0, and hence Ixx + Iyy &lt; 0, and negative Laplacian means that (x, y) is a ‚Äòbright point‚Äô, i.e. a point that is brighter than its neighbors.
Images of (a) human mammary fibroblasts and (b) mouse pre-adipocytes (positive control) grown under conditions that support adipocyte differentiation for 5‚Äì7 days before being fixed and stained with hematoxylin and Oil Red O.



From a computational perspective, we have the following definition: a point is a bright (dark) elliptic feature at scale œÉ if the Hessian matrix of I(x, y; œÉ) is negative (positive) definite at that point. The net result of applying dark elliptic feature detection is a binarized mask corresponding to foreground and background. However, very small regions may have been created as a result of inherent noise in the image, which are then removed based on a size threshold. The threshold is determined by the correct segmentation for a population of nuclear features. In rare cases, the mask corresponding to the dark elliptic features may be corrupted by foreign objects, which can be resolved and corrected after signal decomposition.

Nuclear regions provide the basis for region-based tessellation along curvilinear boundaries. Formally, let Ni correspond to the i-th ‚àà[0, K) nuclei in the image, q ‚àà Ni, and p be a point in the image. Then region-based tessellation is defined by Vi = {p|dist(p, Ni) &lt; dist(p, Nj), j ‚àà {0, 1,‚Ä¶, K ‚àí 1} and j ‚â† i where dist(p, Ni) = minq‚ààNi|p‚àíq|. Computationally, this tessellation is computed through the application of the watershed method (Vincent and Soille, ) to the distance transform that is computed from binarized nuclear masks (Jan and Hsueh, ).

3.2 Signal decomposition
Signal decomposition, through color unmixing, aims to identify the signaling macromolecules that are associated with each dye. For example,  shows how labels for nuclei and lipids are distributed in the RGB space. The main contribution of this article is in characterizing color unmixing as a segmentation problem that incorporates neighborhood information through a global optimization framework. The optimization framework is based on the graph-cut method (Boykov and Marie-Pierre, ), which is briefly summarized. In this context, the image is represented as a graph , where  is the set of all nodes, and ƒí is the set of all arcs connecting adjacent nodes. Usually, nodes and edges correspond to pixels (ùí´) and their adjacency relationship, respectively. Additionally, there are special nodes that are known as terminals, which correspond to the set of labels that can be assigned to pixels. In the case of a graph with two terminals, terminals are referred to as the source (S) and the sink (T). The labeling problem is to assign an unique label xp (0 for background, and 1 for foreground) for each node , and the image cutout is performed by minimizing the Gibbs energy E (Geman and Geman, ):

where E1(xp) is the likelihood energy, encoding the data fitness cost for assigning xp to p, and E2(xp, xq) is the prior energy, denoting the cost when the labels of adjacent nodes, p and q, are xp and xq, respectively. The likelihood energy is computed in an eight-connected neighborhood.  shows how a local neighborhood is partitioned through a two-terminal graph-cut segmentation.
An example of two-terminal (class) graph-cut segmentation: (a) an image grid (3 √ó 3), where ‚ÄòF‚Äô and ‚ÄòB‚Äô correspond to foreground and background seeds, respectively; (b) a graph constructed from image (a); (c) an optimum cut shown as a red line; and (d) a final labeling result where grid points are assigned to terminals S and T after the cut.



The optimization algorithms could be classified into two groups: Goldberg‚ÄìTarjan ‚Äòpush-relabel‚Äô methods (Goldberg and Tarjan, ), and Ford‚ÄìFulkerson ‚Äòaugmenting paths‚Äô (Ford and Fullkerson, ). The details of the two methods can be found in (Cook et al., ).

We initialize our system with multiple models of foreground and background, specified by the user stroke, from a subset of images. An underlying feature distribution, corresponding to a user stroke, is then represented with the Gaussian mixture model, in the color space, i.e. each foreground and background signature is not represented with a single Gaussian model. Let the conditional density for a pixel feature, Cp, belonging to a multi-colored object ùïÜ be a mixture with M component densities:

where a mixing parameter P(j) corresponds to the weight of component j and where Œ£j=1M P(j) = 1. Each mixture component is a Gaussian with mean Œº and covariance matrix Œ£. In RGB color space:

Then the data fitness term is defined as,

in which GMMF(Cp) and GMMB(Cp) are the probabilities of feature Cp (in RGB space) from the foreground and background models, respectively. For example,


where M = 10 was manually selected in our implementation to capture wide variations in staining. P(j) and (Œºj, Œ£j) for p(Cp|j) are estimated by EM algorithm (Tomasi, ). And the smoothness term is defined as,

where |Cp‚àíCq| is the Euclidean distance between feature vectors of Cp and Cq in RGB space, and dist(p, q) is the Euclidean distance between p and q in the image grid. Next, we construct the graph G according to  and optimizing the objective function with the graph cut algorithm (Boykov and Marie-Pierre, ). After decomposition, nuclear segmentation is further validated by removing nuclear candidates that partially overlap with the signaling molecule. However, such an overlap is a rare event, and it is always due to sample contamination in a small area. In cases where macromolecules of interest are localized in nuclei, then the experiment needs to be designed properly, i.e. (i) assure that the dye has sufficient color separation with nuclear labeling hematoxylin, (ii) use another dye for labeling nuclei or (iii) label for cytoplasm as a reference. IHC is a visualization and scoring protocol for pathologists, and staining is always designed properly to assure color separation.
Edge weights for the graph construction, where ‚Ñï is the neighborhood system, and Œº is the weight for smoothness

Edge	Weight	For	
p‚ÜíS		p ‚àà ùí´	
p ‚Üí T		p ‚àà ùí´	
we(p, q)		{p, q} ‚àà ‚Ñï	



3.3 Validation with synthetic data
To evaluate the performance and error rate of the system, a synthetic image has been generated that simulates the nuclear size, shape and contrast associated with complexes. Nuclear size and shape are derived from the average behavior of nuclear features, following segmentation, from a subset of images. Contrast is derived from the user-based annotation of regions corresponding to positive and negative staining from the same subset of images. Gaussian noise is added, and the signal-to-noise ratio is changed from 12 dB to 0 dB, from left to right, respectively. Subsequently, segmentation error is quantified against the ground truth, and results are summarized in  and . This error corresponds to mismatches (e.g. differences) between the known prior mask and the computed segmentation.
Noise is added to a synthetic image at 12 dB (a), 7 dB (b), 3 dB (c) and 0 dB (d), and the segmentation results based on graph cut (Œº = 100) and NMF are shown in the second and third rows, respectively.


Comparison of segmentation errors for synthetic images of  based on graph cut and NMF, respectively

Method					
Graph cut	0.5%	1.2%	3.5%	5.4%	
NMF	0.8%	4.7%	31.2%	43.3%	
Errors are measured against known ground truth.




3.4 Comparison with NMF
 shows the signal decomposition results of the image in , based on graph cut and NMF with identical initialization. We used an improved version of NMF, based on sparseness constraints. The matlab code is available online (Hoyer, ), and has been rewritten in C++ for comparative analysis. The sparseness constraint enables discovery of parts-based representation, and is shown to have a better quality than standard NMF. The results indicate that NMF decomposition is more noisy, mainly because it ignores neighborhood information. Other linear unmixing techniques may also produce noisy output, since regularization is often ignored. It is important to note that NMF is inherently a gradient descent method, and therefore, user-based initialization remains an integral component. Otherwise, the method converges to a wrong fixed point.
A comparison of signal decomposition by graph cut (Œº = 100) (a) and NMF (b) indicates superior performance with the graph-cut method.



Finally, with respect to the computational complexity, the costs for graph cut and NMF, based on the same image (1280 √ó 960), are 10 s and 10 min, respectively.

4 SIGNAL DECOMPOSITION WITH COLOCALIZED SIGNALS IN THE COLOR SPACE
In the previous example, the signal from Oil Red O is registered outside of the nuclear regions, and therefore there is little overlap between stains in the color space. In order to examine the efficacy of our proposed method for colocalized staining, we imaged samples stained for phosphorylated Œ≥H2AX, which localizes to the nucleus. In this experiment, the user provides examples of signals associated with each stain for establishing the prior knowledge. Subsequently, energy functions were computed according to , and optimal partitions were computed. An example, shown in , indicates postive and negative staining, where the results are examined against manual scoring. We have used three representative images from a dataset for comparative analysis. These three images that were selected to represent a diverse signature of samples, were scored by a pathologist, and then compared with automated analysis. Because the process is tedious, a minimal number of images have been selected. Results are shown in , where the second and third columns correspond to the number of positive-and negative-stained nuclei that have been misclassified when compared to the ground-truth data. The last column lists the total number of cells in each image. The average error is &lt;5%.
Decomposition (Œº = 100) of color space when nuclear and antibody stains colocalize: (a) a bright field image of human mammary tissue stained for phosphorylated Œ≥H2AX and hematoxylin, and (b) its color decomposition.


Number of misclassified nuclei in each image for positive and negative stains, followed by the total number of cells in each image

	No. of positive nuclei	No. of negative nuclei	Total no. of cells	
Image 1	10	8	715	
Image 2	17	12	395	
Image 3	4	7	381	



5 BIOLOGICAL INVESTIGATION: A CASE STUDY
We have applied our method to a dataset of 192 images of fibroblasts obtained from women from two distinct patient populations. These samples are imaged on a Nikon Eclipse TE 2000 E, which is equipped with a color camera with a spatial resolution of 1280 √ó 960 pixels and a dynamic range of 8 bits per channel in RGB space. The illumination power is maintained at the same level, and all images are automatically corrected for shading and non-uniformities against a blank slide. Images are processed, and the amount of lipid is quantified for each cell in each image. The net result of color decomposition is a binarized mask, shown in red in , corresponding to positive stains, where the intensity in the red channel is aggregated on a cell-by-cell basis. In addition to color decomposition,  indicates nuclear position, in green, and how the space between nuclear regions are partitioned through region-based tessellation, in yellow. Tessellation allows the signal complex to be associated with the corresponding nuclear region. The binarized masks provide the context for aggregating intensity features in the red channel, and associating them to each nucleus. Finally, the results are represented as two probability density functions for each population, as shown in . The KS test between these two distributions computes a P-value of &lt;0.0001, thus indicating that the two populations are different.
Probability density functions corresponding to the fat content on a cell-by-cell basis for each of the two populations, where (a) corresponds to a population represented by  and (b) corresponds to a population represented by . The KS test computes a P-value of 0.001 indicating that these two populations are different.


Segmentation and color decomposition from two images in the dataset indicate how region-based tessellation enables quantifying signal macromolecules on a cell-by-cell basis. (Œº = 100, œÉ = 2.5)



One of the concerns regarding population study is due to the impact of error in nuclear segmentation for aggregating lipid signals. Our experience indicates that the error in nuclear segmentation is less than a few percent. Therefore, given a very large population of cells, such an error will be buried as noise. It will only be an issue if the central question is to search for outliers in a study.

6 CONCLUSION AND FUTURE WORK
We have developed a novel method for signal decomposition in the color space for scoring the amount of staining associated with macromolecules. The method is based on graph cut, which has a superior performance to NMF. Subsequently, strength of staining is associated to each cell through nuclear segmentation and region-based tessellation. In addition, we have demonstrated the efficacy of our method in samples when the stains are co-localized in the same subcellular regions. Our method has been applied to a dataset of fibroblasts derived from the two patient populations that are different when placed under adipocyte differentiation conditions. Our continued research will focus on other end points for these primary cells in order to visualize and quantify a more comprehensive representation of active macromolecules.

ACKNOWLEDGEMENTS
Authors thank Dr Colleen Fordyce and Dr Kurt Thorn of UCSF for cell-culture support and imaging expertise.

Funding: National Cancer Institute (1P01CA107584-01A1); US Department of Energy, Office of Biological and Environmental Research (DE-AC03 SF0098).

Conflict of Interest: none declared.

