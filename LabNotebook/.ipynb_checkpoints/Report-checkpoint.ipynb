{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statements\n",
    "The problem needs to slove here is, given a bunch of unlabeled documents, and given a word, how to find semantic related words?\n",
    "\n",
    "Why this problem is important? In order to solve this problem, a serial of subproblems need to be solved too, like topic detection, semantic analysis, etc. All these problems are crital to speech and text processing, in other words, they are critial for computers to understand human's languages.\n",
    "\n",
    "###\tDesign experiments to test these hypotheses\n",
    "*   Collect the corpus. (Documented as text files)\n",
    "    I use PubMed bio-documents as my corpus. Here is the [link](ftp://ftp.ncbi.nlm.nih.gov/pub/pmc/) to their website.\n",
    "*   Select Model\n",
    "    The algorithms and models are one of the most important parts for sloving this problem. As far as I know, there are two ways to solve this problem. \n",
    "    1. Ranking words by repeated co-occurrence. The co-occurrence is mearsured by tf-idf, that is for the words that apprear along with target word in documents, then words with higher td-idf score are ranked higher.\n",
    "    <img src=\"images/f1.png\" style=\"border:none;\"> <br>\n",
    "    2. Ranking words based on Conditional Probability. Here is the formula:\n",
    "    <img src=\"images/f2.png\" style=\"border:none;\"> where z is a topic, Z is the topic collection, Wt is target word, Dt is the collection of the document. <br> \n",
    "    \n",
    "    \n",
    "    Eventually I chose the second method. The second topic based model is a better way to who the semantic relationship among words. The documents themselves are reprented by topic distributions. Then the occurrence probability of word in document is also conditional determined by topic distribution. Topic is actually a random variable of words occurrence, in others words, it is a vocabulary with word specific probability. So topic is a good way to model semantic. The first idea just ingore the semantice features.\n",
    "*  Feature extraction\n",
    "    1. I use MALLET libary, which is a java implementation of Latent Dirichlet allocation topic model, to compute topic distribution of documents.\n",
    "    2. Base on topic model, word-topic counts are computed.\n",
    "    3. The platform that runs my feature extraction code, has two, four core Xeon E5345 processor (2.33GHz, 8M L2 cache, no hyper-threading), 16GB memory and hard disk(15000RPM).\n",
    "    \n",
    "\n",
    "* Metrics<br>\n",
    "After careful consideration, eventually I dicided not use metrics to measure the result. There are a few reasons why I make such decision. The first reason is there is no obvious baseline approach. Randomly picking up words is not a good baseline. Of course I can choose another way as the reference but it is hard to tell which one is better, then it is hard to say which one should be baseline. The next reason is I believe evaluatation can only be based on specialists. So human labels and evaluation is better.\n",
    "  \n",
    "###\tRecord your experiments and the exact parameters/methods used\n",
    "The main model I used is LDA topic detection. MALLET is a java library that implements LDA. There are two parameters:\n",
    "<ol type=\"a\">\n",
    "  <li>The number of topic to detect. Currenct model is kind of unsupervised learning. So there is no labels on corpus. Then how many topics in corpus is a big problem. Less topics are easy to compute, but may cannot distinguish words. More topics are computational expensive, but may help me fetch higher semantic related words. I use 200 topics.</li>\n",
    "  <li>The number of iteration for parameters updating. For LDA model, usually 1000 to 2000 interations are preferred. I use 1000 iterations here.</li>\n",
    "  <li>The number of desired words. For given words, I fetch top 10 words from semantic similarity ranking list. For each word out of this fetched 10 words, I fetch 3 words, so total 30 words form up the second level list.</li>\n",
    "</ol>\n",
    "###\tRecord the results of your experiments\n",
    "###\tInterpret and connect the pattern of experiment results\n",
    "###\tDevelop a narrative elucidating what you have discovered\n",
    "###\tIdentify actionable information obtained\n",
    "###\tIdentify insights that may lead to actionable information, as well as a description of what that actionable information may ultimately be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
