1 Introduction
With recent advances in multi-unit recording techniques, there is a growing need for quantitative methods that can accurately detect stimulus-specific neural activity. In this paper, we propose a quantification of the sensitivity of neural responses to external stimuli. We consider two approaches: one based on Fisherian statistical testing, and another estimating a bound on the probability of a neural response.

The concept of sensitivity can be better understood by the contrast between “specialist” and “generalist” of neurons (). Specialists respond to specific stimuli and are vital for discrimination, when, for example, the animal needs to decide between odors. Generalists, on the other hand, respond to multiple stimuli and play a key role in extracting and discovering common features.

We formulate sensitivity measures and apply them to data provided by  to assess the sensitivity of Kenyon cell responses over time in the mushroom body (MB). This area is the second processing layer in the insect brain and is known to be critical for memory formation and the discrimination of odors (; ; ; ; ; ; ; ).

The insect olfactory pathway starts at the antenna, where a massive number of receptors encode the odor stimulus in a high-dimensional code. In locusts, this number is approximately 90,000. This information is then sent to the antennal lobe (AL) for additional processing. In the locust AL approximately 1,000 neurons perform this task. The AL exhibits complex dynamics produced by the interaction of its excitatory and inhibitory neural populations (; ; ). The excitatory cells are called projection neurons because only they transmit the result of AL processing to deeper regions. The projection neurons deliver the AL output to the 50,000 cells of the MB. This is the area where the data under analysis was obtained (). We present a schematic representation of the insect olfactory pathway in the locust in Fig. .
Description of the structural organization of the first few processing layers in the olfactory system of the locust



The paper is organized as follows. First, we outline the analyzed data set. Next, we define neural sensitivity and describe a method to estimate the response probability, which is required in quantifying the sensitivity. Finally, we apply the proposed method to real data from the olfactory system of the locust and show how it can be used to analyze the temporal evolution of sensitivity.

2 Description of experimental data
The recorded MB neurons are the Kenyon cells (KCs). In the experimental setup, 17 different odors were presented to the antenna of the locust for 1 s each. On average each odor was presented ten times and odor presentations were spaced 20 s apart (see Fig.  for a typical trial time protocol in the odor presentation). Tetrode recordings were obtained from KCs and a spike-sorting algorithm was used to detect individual spikes ().
Stimulation protocol: the first odor pulse was initiated at t = 3 s and lasted for 1 s. Each odor was repeated ten times. We estimate the probability of response to spike recordings of 43 Kenyon cells (KC) from 6 experiments reported in . The response of each KC was recorded in the presence of each of the 17 odors. The time frames Δt3 and Δt3.5 are explained in Sect. 



3 Sensitivity and detection of the neural response
We define sensitivity as the distribution of neurons that respond to n out of N stimuli. This definition requires the detecting whether or not a neuron responds to a particular stimulus. The straightforward approach is to use statistical testing by discriminating between two mutually exclusive hypotheses: response and the absence of it.

To code the neural output, we count the number of neural spikes s1, s2, …, sn in n different presentations of the same odor in a given time window. Thus, the observable is the neural activity represented by the number of spikes observed in certain equal-length intervals. The probability distribution of the number of spikes, s1, s2, …, sn, depends on whether a neuron is responsive to a presented stimulus r = R or not . The null hypothesis  is the default activity which is the case when the neuron does not respond. The alternative hypothesis, H1 : r = R, represents the response to the stimulus. We now consider testing the simple null hypothesis  versus an alternative hypothesis H1 : r = R. Now, we have a decision problem between two alternative hypotheses.

Let us discuss different approaches that can help by tackling the problem from different angles. The simplest method is the Fisherian test (), which is known as the standard tail test of the null hypothesis. It is possible to use this because the probability distribution of the null hypothesis, ), is known. Basically, by using this test, one can examine whether the number of neural spikes s1, s2, …, sn is uncommon or infrequent with respect to what is measured as normal to a given confidence level α. The results of this test are in Sect.  and will be compared to others.

One can argue that this test misses all the information available during the stimulation window, although Fisherian supporters would say this extra information is not necessary. There is some debate about Fisherian testing versus other tests (), nevertheless it is not our goal to enter the debate here.

The second statistical test, we consider derived from the Neyman-Pearson lemma (). Unfortunately, this test cannot be used on our experimental data but is worth explaining to state what is missing in our formulation. Neyman and Pearson show that the optimal test function is the ratio of the likelihood functions corresponding to the hypotheses. This statistical test is named the likelihood ratio test and in terms of our problem can be formulated as .

We define the probability of having s1, s2, …, sn responses in n different presentations of the same odor when we know for a fact that there is response to the presented odor as P(s1, s2, …, sn|r = R). The likelihood function L(r = R|s1, s2, …, sn) corresponds to this conditional probability function, P(s1, s2, …, sn|r = R), considered as a function of its second argument with its first argument held fixed in the observed sample of the experiment. We can use the analogous conditional probability, ), in order to calculate the likelihood function ) in the context of the null hypothesis. Within traditional tail-testing, we can reject the null hypothesis when λ ≥ λc, where λc is determined by a confidence level  ().

In order to apply the likelihood ratio test, we need to calculate the likelihoods of the hypotheses. We need to estimate the conditional probabilities  and . While we can comfortably assume that  is equivalent to the baseline activity, the density P(s1, s2, …, sn|r = R) is out of reach because it is not necessarily possible to force a neural response by means of external stimulation. This is the main problem that makes impracticable the application of a likelihood ratio test to decide if a neuron is responsive or not to a given stimulus.

To avoid these problems, we develop a different approach which is based on a data-driven Bayesian framework. The Bayesian approach enables the estimation of a bound on the probability of having a response. This is an additional advantage in contrast to straightforward Fisherian testing. In order to infer a possible positive response to perturbation, we observe some random variable of this system, i.e. an observable that we will name O. An observable is a property of the system state that can be determined by some sequence of physical measures. Therefore, the density P(r = R|O = o, S = s) is the probability of a neural response given a specific observation O = o of the system and the specific stimulus applied S = s. When this probability is close to one, the system has a positive response to the applied stimulus. The complementary probability or negative response probability, , to the stimulus is given by . Let us apply Bayes’ theorem (P(A|B)P(B) = P(B|A)P(A)) to the conditional or posterior probability  to obtain , where  the “prior” probability for the nonresponse random variable. It is “prior” in the sense that it does not take into account any information about the stimulus. The estimation of  represents the probability distribution of the observable when we know for a fact that the system does not respond to the stimulus. At this point, we count on the probability distribution of the observable in the absence of the stimulus (i.e. S = no), which is the resting state or baseline activity of the system and is available in our data set. Then, we can write . This equality follows from two assumptions: if the system is not responding to a specific stimulus, it may be because (i) the stimulus is actually absent (i.e. ); or, (ii) because the observation o is indeed irrelevant whether the system responds or not in the absence of stimulus, which is to say that .

In a great variety of problems, another unknown probability which is difficult, if possible, to estimate is the “prior” probability . However, we know that . such that .

Finally, we can express the complementary probability for no response as .

We name the right-hand side of this equation as the lower bound of the probability of positive responses to the stimulus. In the following section we specify the lower bound for the problem which is needed to estimate the sensitivity of the neuron responses.

4 Derivation of the lower bound of the response probability to odors
We are going to describe the estimation of the response probability for the example of insect odor stimulation. The probabilistic framework can be adapted to detect generic neural responses to any external stimulation. Let us start by defining the window where we can measure the conditional response to a external stimulation. This probability estimation will be used later to determine whether a neuron responds or not to the stimulus and will be compared to Fisherian testing and to another standard method.

A given neuron can spike s times in a time window of Δtp seconds where s = [0,∞), and the index p denotes the time placement of the window measured in seconds from the beginning of the trial. For instance, in Fig. , two examples of Δtp = 1.5 s located at times p = 3 and 3.5 s, respectively (Δt3 and Δt3.5) are shown. To determine whether a given activity is the result of noise or indeed due to the applied stimulus, we first analyze the baseline activity of individual neurons. We denote by R the event that represents the response of the neuron to the odor, and  is the lack of response to the external stimulation. We then proceed to estimate the probability of having s responses given that the odor is not present for all the KCs under analysis. We calculate the probability that a neuron responds given a specific odor and a set of spike observations s1, s2, …, sn in n different presentations of the odor, that is, P(R|s1, s2, …, sn, odor). Hence odor in the formula represents a particular odor from the space of all possible odorant stimuli. As we will see below it is easier to tackle the problem if we calculate , odor) and then use it to estimate a lower limit of the response probability.

In order to calculate the probability , odor), we apply Bayes’ theorem (P(A|B)P(B) = P(B|A)P(A)) to obtain .

As explained in the previous section, the estimation of , odor) captures the activity of the neuron when we know for a fact that there is no response to the odor. Since we count on the baseline activity, we can assume that it is equivalent to estimating , odor = baseline). In other words, we take the baseline activity as an estimator of the typical activity to  to an odor. Let us continue by using . The event si depends on the previous events (si−1, …, s1), which means that P(s1, s2, …, sn|odor) = P(s1|odor)Πi=2nP(si |si−1, …, s1|odor). It is the case that for a given odor presentation we have a unique sequence (sn, …, s1) which is not enough to build an estimation of the conditional probability. If the stimulus presentations are well separated in time the assumption of statistical independence can be appropriate. Nonetheless, there can be some other processes in the system as a result of adaptation and learning that can carry over correlations. In order to account for this situation we can use a first order dependence P(s1, s2, …, sn|odor) = P(s1|odor)Πi=2nP(si |si−1, odor). As we will show on the analyzed data set, there may be no need for this addition, but we include it in the formulation for the sake of the generality of the response probability derivation. One could use higher order dependencies as well, but this requires larger amounts of data to populate the conditional probabilities.

Using the first order dependence we obtain: .

The probability P(si|si−1, odor) will be estimated for different time window sizes, Δtp, from different starting points after the odor presentation in 10 different trials of the same odor. The a priori probability of having a response given a specific odor, , is unknown. However, we do not need this prior, because the lower bound on the probability distribution masks it. We know that .

Since we want to determine whether a given KC responds to the odor, we fix a probability response bound pr such that

P(R|s1, s2, …, sn, odor) ≥ pr,

which together with () and the fact  leads to .

As a result, every KC that fulfills the above inequality is declared as being responsive to the odor with at least pr probability value. We define the lower bound estimator of P(R|s1, s2, …, sn, odor) as: .

In other words, first we set the probability response bound pr and then we build up the probability distributions in the absence of the odorant P(si |si−1, baseline) and under its presence P(si |si−1, odor). Then, we calculate Φ(R|s, odor) at a specific odor presentation for the given KC.

For our particular data set, the correlations from one presentation to the next are very small. The time separation between presentations is long enough and the activity of the neurons is very low. In addition, when the Kolmogorov-Smirnov test is run to reject the hypothesis that P(si|si−1) = P(si) for all the KCs we do not find a KC that can reject the hypothesis at the 10% significance level. In fact, the average p-value is 0.8 for the baseline activity and 0.7 during odor stimulation.

Therefore, the inequality () can be expressed in a simpler form as .

The main advantage of the lack of correlations across trials is that the conditional probabilities can be populated with fewer trials. To calculate the lower bound estimator in the above equation we need to estimate the probability distributions P(si|baseline) and P(si|odor). Although it is common to assume that neurons follow a Poisson process, the MB neurons do not follow a Poisson distribution. As suggested by  and , instead of assuming a parametric probability distribution (as used, for example, in Bayesian decoding schemes) we use direct bootstrapping to obtain non-parametric distributions.

Bayesian bootstrap with non informative priors has been used to estimate posterior distributions (). Parametric probability distributions can be handled theoretically, but for this paper, we opted out of that path and decided to pursue the avenue opened by . In Fig.  we calculate a typical sensitivity curve from the recorded KCs when 17 different odors were presented to the antennae of the locust for 1 s each (see Sect. ). As we defined in Sect. , neural sensitivity is the probability that a neuron responds to n out of N odors, P(n|N). In other words, P(n|N) is the number of neuron responses divided by the total number of available neurons in the experiment. The neuron responses used in this sensitivity curve have been calculated using the above formalism for a specific time window of Δt3 = 1 and probability response bound pr = 0.99. In this example, the maximal sensitivity corresponds to a two-odor response. The next significant bump in this curve corresponds to a positive response of 9 odors out of the 17 presented during the experiment. One can see that this event is less likely than the response to two odors. Basically, we can see that most of the KCs are sensitive to two odors, while there are others that have a broader tuning.
Sensitivity curve calculated from the recorded KCs when 17 different odors were presented to the antennae of the locust for 1 s each (see Sect. ). The discrete sensitivity distribution for a specific high baseline value of 12 s is presented as bars. We used for this analysis a time window of Δt3 = 1 s. The response bound was pr = 0.99. It is the lower bound of the probability of having the neuron respond to a given odor. We use a Gaussian distribution with dispersion equal to 0.6 to smooth the discrete sensitivity distribution



5 Estimating the conditional response to Kenyon cell data
We have used several KC recordings published in  in order to build a distribution of the sensitivities of the KCs to odor’s presentation. Each neuron responded to a percentage of the presented odors. At every data point in the sensitivity distribution, we placed a Gaussian distribution to densely populate the curve. We analyzed spike recordings of 43 KCs from 6 experiments, in which 17 odors were presented to the animal. For each odor 10 trials were recorded.

The goal of the analysis is to determine the level of sensitivity of the KCs as a function of the time interval Δtp (see Sect. ). In Fig.  we show that for small sizes of Δt3 (between 0.1 and 1.0 s) there is a transient in the sensitivity curves. At the early stages of the odor presentation the KCs are very selective. After half-a-second, the KCs widen their selectivity to quite a few odors. Thus the response curves become quite stationary for sizes, Δt3, between 1.0 and 2.0 sec. To analyze the transient response after odor stimulation we run the response window, Δtp, at different starting points between p = 3 and p = 4.6 with constant Δtp = 1. This helps in understanding the temporal coding properties of the KC response. In the initial stages, the KCs are very selective to the odors (see Fig. ), but after half-a-second, the selectivity to odors broadens (see right panel in Fig. ). Thus, the KCs become more sensitive to more odors as time passes. After the odor is removed, the selectivity distribution returns slowly to normal. The reason is that the AL is known to produce complex spatio-temporal patterning after odor removal (see  for details).
Sensitivity surface as a function of the time window Δt3. We use a Gaussian distribution with dispersion equal to 0.6 to smooth the sensitivity distribution. One can see the difference between the transient stage (for values of Δt3 between 0.1 and 1.0 s) and the stationary state (see blow up in figure for values of Δt3 between 1.0 and 2.0 s)

a The sensitivity as a function of the placement of the time window at time t. The size of the sliding window is 0.5 s. This graph helps to elucidate the role of time during the transient response to odors in the KCs. b A blow up for values of number of odors between 6 and 17. c The maximum number of odors that the neurons respond to as a function of the placement of the time window. It follows that the sensitivity of some neurons becomes broader in time



5.1 An example of the calculation of neuron response probability
To illustrate the neural response calculation, let us show an example of our method applied to a specific neuron. In this example, we choose a time window of Δt3 = 1. In Fig. , the spike raster and its peristimulus time histograms (PSTHs) are depicted. The calculation for the lower bound estimator of response probability gives us a value of Φ(R|s1, s2, …, sn, odor) = 1, which means that this KC responds with high probability to the specific odor presentation. One can see that the KC is significantly excited by the stimulus. In the corresponding PSTHs, one can see the probability distributions used to obtain the lower bound estimator, Φ. The factors of these probability distributions of () are calculated by means of a bootstrap procedure and some of them are shown in Table . The right panel in the same figure represents the control for the baseline activity. We calculate the lower bound estimator (1−Φ) as a function of the placement of the time window response at time t. The maximal probability of the response is precisely situated on the stimulation period.
An example of a spike raster for one KC. The time window used was Δt3 = 1 s (indicated by vertical bars). In the PSTHs, we show the probability distributions used to calculate the lower bound estimator. Φ on (). The values of the factorized probabilities can be seen in Table . These probabilities are estimated by means of a bootstrap procedure (see for details ). This neuron responds significantly for this particular odor with the lower bound of the probability response to 1.0. The right panel is a baseline control for the same neuron. 1 − Φ is represented on a logarithmic scale as a function of the placement of the time window. It can be seen that the maximal reliability occurs precisely on the window of the stimulation. The dashed line corresponds to a probability response bound of pr = 0.99. All the points that are below this line are classified as responses

Non-parametric probability distributions calculated through a bootstrap procedure from the spike rasters shown on Fig. 

# of spikes in δt3 = 1s	P(s|odor)	P(s|baseline)	
s = 0	0.1019	0.846327	
s = 1	0.2045	0.119967	
s = 2	0.3976	0.026	
s = 3	0.0962	0.00680667	
s = 4	0.1998	0.0	
We use these distributions to calculate the lower bound estimator, Φ, of P(R|s1, s2, …, sn, odor)



6 Method comparison
A method commonly used to detect whether a neuron responds to a stimulus or not consists of measuring the mean firing rate over fixed periods of time during baseline activity. This set of mean firing rates is used to estimate the standard deviation of the baseline activity. For example, in , neural baseline statistics were used as a reference to determine a yes/no response. When the stimulus is presented, if the firing rate becomes significantly higher than the baseline activity then it is said that the neuron has fired. The arbitrary part of the method is to determine how much significance is needed. The strategy consists of fixing n times the standard deviation and then by “visual inspection” determining whether it is good enough. This standard method resembles Fisherian or tail testing under the assumption that the firing distribution respect to the baseline activity is Gaussian. Then the confidence level to reject the null hypothesis (baseline activity) is . This method itself does not provide an estimate or probability of how accurate the arbitrary determination of n is. Rather than relying on visual inspection, the most straightforward method is Fisherian testing directly calculated from 
 as mentioned in Sect. . In addition, one can use our lower bound estimation () as an alternative that provides more information about the probability of response of a neuron.

In the Fig. , we present the overall comparison among all methods. We use the same critical values for all methods. For our method, we chose the different probability response bounds of pr = 0.9, 0.99. In the standard method, we use 1.281 and 2.326 standard deviations which correspond to 90 and 99% of Gaussian area respectively. Last, we have introduced the standard tail test (see Sect. ) as the lower bound in the comparisons using values of α = 0.1, 0.01. Black boxes in each panel mean that a response to the odor exists. One can see that the probability bound method is the most restrictive of the three in assessing whether a neuron responds to certain stimulus. For instance, our method gives a total of 197 responses for pr = 0.99. The standard method has 236 for the equivalent case and 250 for the Fisherian test. All the responses produced by the lower bound limit for pr = 0.99 are present in the Fisherian testing, while there are three cases that differ with respect to the standard method (nSDs = 2.326). In the same figure, it is observed that the Fisherian test is least restrictive. Remember that the Fisherian test only has information about the probability distribution of spikes in the baseline, . In this sense, the Fisher test is a mask for the lower bound method. However, the lower bound method with additional information during the stimulation window makes the decision process more restrictive. Additionally, when one compares the different methods it can be estimated by visual inspection which is the probability of response that corresponds to the arbitrary selection of the n times the standard deviations or the α parameter for the Fisherian test. We can see that values of 2.326 standard deviations and α = 0.01 for the Fisherian test are associated with a probability of response less than pr = 0.9. This provides an idea for the cutoff for response probability when one chooses parameters in the other methods.
Here we provide a direct comparison among the lower bound estimation (pr = 0.9, 0.99), the standard method of n standard deviations (nSDs = 1.281, 2.326) and the Fisher test (α = 0.1, 0.01). The sensitivity curve for pr = 0.99 is plotted in Fig. . The stimulus time window used was Δt3 = 1 sec



Within the scope of the methods analyzed in this work there are techniques based on statistical change-point detection. They are normally used to estimate the latency of the neural response after presentation of a stimulus (; ; ). A useful approach for detecting abrupt changes in the spike activity in real time is given by . This method requires knowledge of the the nature of the interspike interval (ISI) probability distribution to compute the detection delay of the neural abrupt response to specific stimuli. The method needs some assumptions about the probability distribution of ISIs before and after presentation of a stimulus (normally the gamma distribution). With these assumptions this method is optimal for solving the detection problem for neural responses to stimuli when we have independent and identically distributed samples of ISIs before and after presentation of a stimulus. In our current approach, we did not want to make assumptions regarding the parametric structure of the probability distribution.

Determining which method works best depends on many factors related to the assumptions of the parametric dependence of the probability distributions, the amount of data, and the system under analysis. It is possible that the best answer to this problem is to use combinations of methods to gain confidence in decisions about neural responses. The method proposed in Sect.  does not assume a parametric probability distribution for spike trains and it also gives a bound for the response probability.

7 Conclusions
We propose a novel method to estimate the sensitivity of neural responses by using the lower bound of the response probability. As discussed in Sect. , we can circumvent the problems derived from likelihood ratio testing (determining the conditional probability distribution to the stimulus and the prior probabilities) by estimating a lower bound of the probability of response and the use of data-driven methods to calculate the probability distributions.

The application to the spiking neurons of the locust MB is just an example. The method can be applied to any recordings of neural responses in the presence and the absence of stimuli. It can be applied to very active spiking neurons or sparse ones. It can also provide high-resolution detection of whether the response is significantly above or below baseline activity.

In addition to the conclusions drawn in , it has been shown that the KCs of the MB have distinct patterns of selectivity depending on whether they fire at the beginning of the simulation (transient dynamics) or at the very end (fixed point). During the transient, KCs are extremely selective while at the end they become more broadly tuned to different odors (see for details Fig. ). This fact suggests that initial stages of the recognition phase carried out in the MB has mostly a quick discriminative role while at the end of the stimulation a more integrative representation is used. The fact that different neurons are broadly tuned allows the system to produce associations between different odors, and permits the extraction of common features across odors.

Finally, we would like to add that, in the process of understanding neural coding and its function, the quantification of neural sensitivity can reveal insights into cortical function. If neurons with low sensitivity dominate, one could suggest the existence of an area whose main function is discrimination. On the other hand, high sensitivities (generalists) may indicate abstraction or predictive areas.

We thank Javier Perez Orive and Gilles Laurent for providing the data. We also want to thank to Thomas Nowotny, Marta Garcia-Sanchez, Rafael Levi, Eduardo Serrano, Pablo Varona, Kerem Muezzinoglu and Sina Tootoonian for their productive discussions. This work was supported by the Spanish Government projects TIN 2007-65989 and Network CAM S-SEM-0255-2006. R.H. acknowledges partial support by ONR N00014-07-1-0741.

Open Access This article is distributed under the terms of the Creative Commons Attribution Noncommercial License which permits any noncommercial use, distribution, and reproduction in any medium, provided the original author(s) and source are credited.

