

   
Biol CybernBiol CybernBiological Cybernetics0340-12001432-0770Springer-VerlagBerlin/Heidelberg2286446851210.1007/s00422-012-0512-8ProspectsActive inference and agency: optimal control without cost functionsFristonKarlk.friston@ucl.ac.ukSamothrakisSpyridonMontagueRead The Wellcome Trust Centre for Neuroimaging, UCL, Institute of Neurology, 12 Queen Square, London, WC1N 3BG UK  School of Computer Science and Electronic Engineering, University of Essex, Colchester, CO4 3SQ UK  Department of Physics, Virginia Tech Carilion Research Institute, Virginia Tech, 2 Riverside Circle, Roanoke, VA 24016 USA 38201238201220121068-95235411220121672012© The Author(s) 2012This paper describes a variational free-energy formulation of (partially observable) Markov decision problems in decision making under uncertainty. We show that optimal control can be cast as active inference. In active inference, both action and posterior beliefs about hidden states minimise a free energy bound on the negative log-likelihood of observed states, under a generative model. In this setting, reward or cost functions are absorbed into prior beliefs about state transitions and terminal states. Effectively, this converts optimal control into a pure inference problem, enabling the application of standard Bayesian filtering techniques. We then consider optimal trajectories that rest on posterior beliefs about hidden states in the future. Crucially, this entails modelling control as a hidden state that endows the generative model with a representation of agency. This leads to a distinction between models with and without inference on hidden control states; namely, agency-free and agency-based models, respectively.

Keywords
Partially observable Markov decision processesOptimal controlBayesianAgencyInferenceActionFree energyissue-copyright-statement© Springer-Verlag 2012

   
We would like to thank Peter Dayan for invaluable comments on this work and also acknowledge the very helpful comments and guidance from anonymous reviewers of this work.

Open Access
This article is distributed under the terms of the Creative Commons Attribution License which permits any use, distribution, and reproduction in any medium, provided the original author(s) and the
source are credited.



   
References
Ashby WR   Principles of the self-organizing dynamic system J Gen Psychol 1947 37 125 128 10.1080/00221309.1947.9918144 20270223 
Axmacher N  Henseler MM  Jensen O  Weinreich I  Elger CE  Fell J   Cross-frequency coupling supports multi-item working memory in the human hippocampus Proc Natl Acad Sci 2010 107 7 3228 3233 10.1073/pnas.0911531107 20133762 
Baxter J  Bartlett PL  Weaver L   Experiments with Infinite- Horizon, Policy-Gradient Estimation J Artif Intell Res 2001 15 351 381 
Beal MJ (2003) Variational algorithms for approximate bayesian inference’. PhD. Thesis, University College London, London
Bellman R   On the theory of dynamic programming Proc Natl Acad Sci USA 1952 38 716 719 10.1073/pnas.38.8.716 16589166 
Berridge KC   Motivation concepts in behavioral neuroscience Physiol Behav 2004 81 2 179 209 10.1016/j.physbeh.2004.02.004 15159167 
Birkhoff GD   Proof of the ergodic theorem Proc Natl Acad Sci USA 1931 17 656 660 10.1073/pnas.17.12.656 16577406 
Botvinick MM, An J (2008) Goal-directed decision making in prefrontal cortex: a computational framework. Adv Neural Inf Process Syst (NIPS) 21
Braun DA, Ortega P, Theodorou E, Schaal S (2011) Path integral control and bounded rationality. In: ADPRL 2011, Paris
Brown LD   A complete class theorem for statistical problems with finite sample spaces Ann Stat 1981 9 6 1289 1300 10.1214/aos/1176345645 
Camerer CF   Behavioural studies of strategic thinking in games Trends Cogn Sci 2003 7 5 225 231 10.1016/S1364-6613(03)00094-9 12757825 
Canolty RT  Edwards E  Dalal SS  Soltani M  Nagarajan SS  Kirsch HE  Berger MS  Barbaro NM  Knight R   High gamma power is phase-locked to theta oscillations in human neocortex Science 2006 313 5793 1626 1628 10.1126/science.1128115 16973878 
Cooper G (1988) A method for using belief networks as influence diagrams. In: Proceedings of the Conference on uncertainty in artificial intelligence
Daw ND  Doya K   The computational neurobiology of learning and reward Curr Opin Neurobiol 2006 16 2 199 204 10.1016/j.conb.2006.03.006 16563737 
Dayan P  Daw ND   Decision theory, reinforcement learning, and the brain Cogn Affect Behav Neurosci 2008 8 4 429 453 10.3758/CABN.8.4.429 19033240 
Dayan P  Hinton GE   Using expectation maximization for reinforcement learning Neural Comput 1997 9 271 278 10.1162/neco.1997.9.2.271 
Dayan P  Hinton GE  Neal R   The Helmholtz machine Neural Comput 1995 7 889 904 10.1162/neco.1995.7.5.889 7584891 
Duff M, (2002) Optimal learning: computational procedure for bayes-adaptive markov decision processes. PhD thesis. University of Massachusetts, Amherst
Evans DJ   A non-equilibrium free energy theorem for deterministic systems Mol Phys 2003 101 15551 15554 10.1080/0026897031000085173 
Feldbaum AA   Dual control theory, Part I Autom Remote Control 1961 21 9 874 880 
Feldman H  Friston KJ   Attention, uncertainty, and free-energy Front Hum Neurosci 2010 4 215 10.3389/fnhum.2010.00215 21160551 
Feynman RP   Statistical mechanics 1972 Reading MA Benjamin 
Filatov N  Unbehauen H   Adaptive dual control: theory and applications (lecture notes in control and information sciences 2004 Berlin Springer 
Fox C, Roberts S (2011) A tutorial on variational Bayes. In: Artificial intelligence review. Spinger, Berlin
Friston K   Hierarchical models in the brain PLoS Comput Biol 2008 4 11 e1000211 10.1371/journal.pcbi.1000211 18989391 
Friston K   The free-energy principle: a unified brain theory? Nat Rev Neurosci 2010 11 2 127 138 10.1038/nrn2787 20068583 
Friston K   What is optimal about motor control? Neuron 2011 72 3 488 498 10.1016/j.neuron.2011.10.018 22078508 
Friston K, Ao P (2012) Free-energy, value and attractors. In: Computational and mathematical methods in medicine, vol 2012
Friston K  Kiebel S   Cortical circuits for perceptual inference Neural Netw 2009 22 8 1093 1104 10.1016/j.neunet.2009.07.023 19635656 
Friston K  Kiebel S   Predictive coding under the free-energy principle Philos Trans R Soc Lond B Biol Sci 2009 364 1521 1211 1221 10.1098/rstb.2008.0300 19528002 
Friston KJ  Daunizeau J  Kiebel SJ   Active inference or reinforcement learning? PLoS One 2009 4 7 e6421 10.1371/journal.pone.0006421 19641614 
Friston KJ  Daunizeau J  Kilner J  Kiebel SJ   Action and behavior: a free-energy formulation Biol Cybern 2010 102 3 227 260 10.1007/s00422-010-0364-z 20148260 
Friston KJST  Fitzgerald T  Galea JM  Adams R  Brown H  Dolan RJ  Moran R  Stephan KE  Bestmann S   Dopamine, affordance and active inference PLoS Comput Biol 2012 8 1 e1002327 10.1371/journal.pcbi.1002327 22241972 
Friston K  Kilner J  Harrison L   A free energy principle for the brain J Physiol Paris 2006 100 1–3 70 87 10.1016/j.jphysparis.2006.10.001 17097864 
Friston K  Mattout J  Kilner J   Action understanding and active inference Biol Cybern 2011 104 137 160 10.1007/s00422-011-0424-z 21327826 
Friston KJ  Tononi G  Reeke GNJ  Sporns O  Edelman GM   Value-dependent selection in the brain: simulation in a synthetic neural model Neuroscience 1994 59 2 229 243 10.1016/0306-4522(94)90592-4 8008189 
Gigerenzer G  Gaissmaier W   Heuristic decision making Annu Rev Psychol 2011 62 451 482 10.1146/annurev-psych-120709-145346 21126183 
Gläscher J  Daw N  Dayan P  O’Doherty JP   States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning Neuron 2010 66 4 585 595 10.1016/j.neuron.2010.04.016 20510862 
Gomez F, Miikkulainen R (2001) Learning robust nonlinear control with neuroevolution. Technical Report AI01-292, Department of Computer Sciences, The University of Texas at Austin
Gomez F  Schmidhuber J  Miikkulainen R   Accelerated neural evolution through cooperatively coevolved synapses J Mach Learn Res 2009 9 937 965 
Helmholtz H (1866/1962), Concerning the perceptions in general. In: Treatise on physiological optics, 3rd edn. Dover, New York
Hinton GE, van Camp D (1993) Keeping neural networks simple by minimizing the description length of weights. In: Proceedings of COLT-93,pp 5–13
Hoffman, M, de Freitas, N, Doucet, A, Peters J (2009) An expectation maximization algorithm for continuous markov decision processes with arbitrary rewards. In: Twelfth Int. Conf. on artificial intelligence and statistics (AISTATS 2009)
Howard RA   Dynamic programming and Markov processes 1960 MA MIT Press Cambridge 
Jaeger H   Observable operator models for discrete stochastic time series Neural Comput 2000 12 1371 1398 10.1162/089976600300015411 10935718 
Jensen F, Jensen V, Dittmer SL (1994) From influence diagrams to junction trees. In: Proc. of the Tenth Conference on uncertainty in artificial intelligence. Morgan Kaufmann, San Fransisco
Kaelbling LP  Littman ML  Cassandra AR   Planning and acting in partially observable stochastic domains Artif Intell 1998 101 1–2 99 134 10.1016/S0004-3702(98)00023-X 
Kappen HJ   Linear theory for control of nonlinear stochastic systems Phys Rev Lett 2005 95 20 200201 10.1103/PhysRevLett.95.200201 16384034 
Kappen HJ   Path integrals and symmetry breaking for optimal control theory J Stat Mech: Theory Exp 2005 11 P11011 10.1088/1742-5468/2005/11/P11011 
Kappen HJ, Gomez Y, Opper M (2009) Optimal control as a graphical model inference problem. arXiv:0901.0633v2
Kiebel SJ  Daunizeau J  Friston KJ   Perception and hierarchical dynamics Front Neuroinf 2009 3 20 
Kiebel SJ, von Kriegstein K, Daunizeau J, Friston KJ (2009b) Recognizing sequences of sequences. PLoS Comput Biol 5(8):e1000464
Kishida KT  King-Casas B  Montague PR   Neuroeconomic approaches to mental disorders Neuron 2010 67 4 543 554 10.1016/j.neuron.2010.07.021 20797532 
Littman ML  Majercik SM  Pitassi T   Stochastic boolean satisfiability J Autom Reason 2001 27 3 251 296 10.1023/A:1017584715408 
Littman ML, Sutton RS, Singh S (2002) Predictive Representations of State. Adv Neural Inf Process Syst 14
MacKay DJ   Free-energy minimisation algorithm for decoding and cryptoanalysis Electron Lett 1995 31 445 447 10.1049/el:19950331 
Montague PR  Dayan P  Person C  Sejnowski TJ   Bee foraging in uncertain environments using predictive Hebbian learning Nature 1995 377 6551 725 728 10.1038/377725a0 7477260 
Moutoussis M  Bentall RP  El-Deredy W  Dayan P   Bayesian modelling of Jumping-to-conclusions bias in delusional patients Cogn Neuropsychiatry 2011 7 1 26 
Namikawa J  Nishimoto R  Tani J   A neurodynamic account of spontaneous behaviour PLoS Comput Biol. 2011 7 10 e1002221 10.1371/journal.pcbi.1002221 22028634 
Neal RM  Hinton GE   Jordan M   A view of the EM algorithm that justifies incremental sparse and other variants Learning in graphical models 1998 Dordrecht Kluwer Academic 
Oliehoek F, Spaan MTJ, Vlassis N (2005) Best-response play in partially observable card games. In: Proceedings of the 14th Annual Machine Learning Conference of Belgium and the Netherlands
Pearl J   Probabilistic reasoning in intelligent systems: networks of plausible inference 1988 San Fransisco Morgan Kaufmann 
Rao RP   Decision making under uncertainty: a neural model based on partially observable markov decision processes Front Comput Neurosci 2010 4 146 10.3389/fncom.2010.00146 21152255 
Rao RP  Ballard DH   Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects Nat Neurosci 1999 2 1 79 87 10.1038/4580 10195184 
Rawlik K, Toussaint M, Vijayakumar S (2010) Approximate inference and stochastic optimal control. arXiv:1009.3958
Rescorla RA  Wagner AR   Black A  Prokasy W   A theory of Pavlovian conditioning: variations in the effectiveness of reinforcement and nonreinforcement Classical conditioning II: current research and theory. 1972 New York Appleton Century Crofts 
Robert C (1992) L’analyse statistique Bayesienne. In: Economica. Paris, France
Shachter RD   Probabilistic inference and influence diagrams Operat Res 1988 36 589 605 10.1287/opre.36.4.589 
Silver D, Veness J (2010) Monte-Carlo planning in large POMDPs. In: Proceedings of the Conference on neural information processing systems
Sutton RS  Barto AG   Toward a modern theory of adaptive networks: expectation and prediction Psychol Rev 1981 88 2 135 170 10.1037/0033-295X.88.2.135 7291377 
Tani J   Learning to generate articulated behavior through the bottom-up and the top-down interaction processes Neural Netw 2003 16 1 11 23 10.1016/S0893-6080(02)00214-9 12576102 
Theodorou E  Buchli J  Schaal S   A generalized path integral control approach to reinforcement learning J Mach Learn Res 2010 11 3137 3181 
Todorov E (2006) Linearly-solvable Markov decision problems. In: Advances in neural information processing systems. MIT Press, Boston
Todorov E (2008) General duality between optimal control and estimation. In: IEEE Conference on decision and control
Toussaint M, Charlin L, Poupart P (2008) Hierarchical POMDP controller optimization by likelihood maximization. In: Uncertainty in artificial intelligence (UAI 2008), AUAI Press, Menlo Park
Toussaint M, Storkey A (2006) Probabilistic inference for solving discrete and continuous state Markov decision processes. In: Proceedings of the 23nd International Conference on machine learning
van den Broek B  Wiegerinck W  Kappen B   Graphical model inference in optimal control of stochastic multi-agent systems J Artif Int Res 2008 32 1 95 122 
Watkins CJ  Dayan P   Q-learning Mach Learn 1992 8 279 292 
Williams RJ   Simple statistical gradient-following algorithms for connectionist reinforcement learning Mach Learn 1992 8 229 256 
Zhang NL   Probabilistic inference in influence diagrams Comput Intell 1998 14 4 475 497 10.1111/0824-7935.00073 



