

   
Behav NeurolBehav NeurolBNBehavioural Neurology0953-41801875-8584Hindawi Publishing Corporation 10.1155/2015/241804Research ArticleSound Richness of Music Might Be Mediated by Color Perception: A PET Study Satoh Masayuki 
1

*
Nagata Ken 
2
Tomimoto Hidekazu 
1

3
1Department of Dementia Prevention and Therapeutics, Graduate School of Medicine, Mie University, 2-174 Edobashi, Tsu, Mie 514-8507, Japan2Department of Neurology, Research Institute for Brain and Blood Vessels, 6-10 Senshu-Kubota-Machi, Akita 010-0874, Japan3Department of Neurology, Mie University Graduate School of Medicine, 2-174 Edobashi, Tsu, Mie 514-8507, Japan*Masayuki Satoh: bruckner@clin.medic.mie-u.ac.jpAcademic Editor: Michael E. Behen

2015 7 10 2015 2015 2418046 3 2015 17 5 2015 Copyright © 2015 Masayuki Satoh et al.2015This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.
Objects. We investigated the role of the fusiform cortex in music processing with the use of PET, focusing on the perception of sound richness. Method. Musically naïve subjects listened to familiar melodies with three kinds of accompaniments: (i) an accompaniment composed of only three basic chords (chord condition), (ii) a simple accompaniment typically used in traditional music text books in elementary school (simple condition), and (iii) an accompaniment with rich and flowery sounds composed by a professional composer (complex condition). Using a PET subtraction technique, we studied changes in regional cerebral blood flow (rCBF) in simple minus chord, complex minus simple, and complex minus chord conditions. Results. The simple minus chord, complex minus simple, and complex minus chord conditions regularly showed increases in rCBF at the posterior portion of the inferior temporal gyrus, including the LOC and fusiform gyrus. Conclusions. We may conclude that certain association cortices such as the LOC and the fusiform cortex may represent centers of multisensory integration, with foreground and background segregation occurring at the LOC level and the recognition of richness and floweriness of stimuli occurring in the fusiform cortex, both in terms of vision and audition.



   
1. Introduction
Historically, the style of music has developed from simple to complex. Such development was typically classified as a change from monophony, that is, music for a single voice or part [1], to polyphony, in which two or more strands sound simultaneously, or to homophony in which there was a clear distinction between melody and accompanying harmony [1]. In music with a monophonic style, only the melody is produced and there is no accompaniment. In homophony, to which most nursery and folk songs of western music belong, music consists of melody and its accompaniment. As music with homophonic or polyphonic styles has developed, harmonies have become more complex. For example, music of Mozart or Haydn in the 18th century rarely utilized dissonant chords, while the 20th century music of Ravel or Debussy had several kinds of chords including dissonant ones. Listening to homophonic music is different from listening to monophonic music according to the following. First, with homophonic music, listeners discriminate melody and its accompaniment. Even if the melody and the accompaniment are played by the same instrument (i.e., with the identical timbre), we can easily and instantaneously perceive the melody and the accompaniment. The neural basis of this is still unknown, but we previously reported in a positron emission tomography (PET) activation study that the lateral occipital complex (LOC), which participates in foreground and background segregation in vision, plays an important role in the discrimination between melody and its accompaniment [2]. The melody and the accompaniment could be regarded, in auditory terms, as the foreground and background, respectively. We suggested that the same neural substrates carried out similar functions beyond the simple discrimination of sensory modalities. Second, the sounds of homophonic music could be richer than monophonic music. The quality of sound is generally called “timbre.” The timbre is operationally defined as the attribute that distinguishes sounds of equal pitch, loudness, location, and duration [3]. The term “timbre” not only relates to the individual musical instrument, but also relates to expressing the characteristics of the sound of musical pieces. For example, it is generally considered that the timbre of impressionist music of Ravel or Debussy is richer and more flowery than the classical music of Mozart or Haydn. In the above-mentioned PET study, the melody with accompaniment also activated the fusiform cortex (in addition to the LOC) compared to the melody without the accompaniment [2]. We interpreted the activation of the fusiform cortex to reflect the rich sound from the accompaniment, but much still remains to be done to identify the role of that area in listening to music.

Over the past few decades, a considerable number of PET activation studies have been made on various aspects of music, sounds, and the brain [4–6], not only in healthy subjects [4, 6] but also in patients with tinnitus [5]. Based on our previous researches, we performed another PET study that investigated brain region activity while subjects listened to melodies with various kinds of accompaniments. Musically naïve subjects listened to melodies of familiar nursery songs with various degrees of sound richness of the accompaniment. According to a visual analogue scale (VAS), for each piece of music we also ascertained to what extent the subjects felt the sound was rich. Using a PET subtraction technique, brain regions that were significantly activated by sound richness were identified.

2. Subjects and Methods
2.1. Subjects
Ten right-handed male volunteers (mean age 21.7 ± 0.95 years; range 20–24) participated in the study. All were students at the Schools of Engineering or Mining, Akita University, and met criteria for Grison's second level of musical culture [7]. None had received any formal or private musical education, and none had any signs or history of neurological, cardiovascular, or psychiatric disease. All subjects gave written informed consent after the purpose and procedure of the examination had been fully explained. The study was approved by the Ethics Committee of the Research Institute for Brain and Blood Vessels, Akita, Japan, and all experiments were conducted in accordance with the Declaration of Helsinki.

2.2. Task Procedures
The stimuli in this experiment were six melodies of well-known Japanese nursery songs. All subjects were very familiar with these melodies. For each melody, the following three kinds of accompaniment were composed: (i) an accompaniment composed by using only three basic chords (tonic, dominant, and subdominant chord), one of which was set on each bar (chord condition), (ii) a simple accompaniment that is typically used in the traditional music text books in Japanese elementary schools (simple condition), and (iii) an accompaniment with rich and flowery sounds composed by a professional composer [8] (complex condition). The (i) chord and (ii) simple condition accompaniments were composed by one of the authors (Masayuki Satoh). The accompaniment of simple condition consisted of quarter tones of a chord on a whole note of fundamental tone. The first beat of each cord in the bar was rest, so only the fundamental tone was played at the first beat. All musical stimuli were played using the “FINALE” software [9]. The author Masayuki Satoh wrote musical scores of musical pieces used in this experiment on the “FINALE,” and the software played each piece with piano timbre. Each performance was recorded on a compact disc. Melodies with the three types of accompaniments were randomly presented. Subjects were instructed to listen to each melody, and PET measurements were obtained while listening to these melodies (procedures described below). Subjects were required to make a sign with the index finger of the right hand as the melody of each song finished. All stimuli were presented binaurally via inset stereo earphones.

The instruction to the subjects was as follows: Close your eyes. You will listen to a melody of a familiar nursery song. If you feel that the melody has finished, please make a sign with the index finger of your right hand.

2.3. Positron Emission Tomography Measurements
The protocol used in this study has been previously described in detail [2, 10–12]. Briefly, PET data were acquired in 3D acquisition mode using Headtome V (Shimadzu, Kyoto, Japan). Scans were performed in a darkened room with subjects lying supine with eyes closed. Nine CBF measurements were determined for each subject, three during the chord, three during the simple, and three during the complex condition. Employing 15O-labeled water (H215O) intravenous bolus technique [13], emission data were collected for 90 seconds for each measurement following intravenous bolus injection of about 15 mL (40 mCi) H215O. A musical piece was initiated 15 seconds prior to data acquisition, followed by another musical piece, and this in total continued for about 120 seconds. Emission data were corrected for attenuation by acquiring 10 minutes of transmission data utilizing 68Ge orbiting rod source performed prior to the activation scans. A wash-out period of approximately 10 minutes was allowed between successive scans. For anatomic reference, all subjects underwent axial T1-weighted imaging (T1WI) and T2-weighted imaging (T2WI) using a 1.5 T magnetic resonance system (Vision, Siemens, Germany). T1WI (TR/TE = 665/14 ms) and T2WI (TR/TE = 3600/96 ms) were obtained using a slice thickness of 5 mm with an interslice gap of 1 mm.

2.4. Data Analysis
PET data analysis was performed on a SGI Indy running IRIX 6.5 (Silicon Graphics, California), using an automated PET activation analysis package [14] composed of six main processing stages which has been previously described in detail [2, 10–12]. The six main stages consisted of intrasubject coregistration, intrasubject normalization, automatic detection of the AC-PC line, detection of multiple stretching points and surface landmarks on intrasubject averaged image sets, intersubject summation and statistical analyses, and superimposition of statistical results onto the stereotactic MRI. Deformation of individual brains to correspond with the standard atlas brain was achieved by spatially matching individual landmarks to the corresponding predefined standard surface landmarks and minimizing correlation coefficients of regional profile curves between the stretching centers. Activation foci were considered to be significantly activated if the corresponding p value was less than a predetermined threshold (p &lt; 0.001, Bonferroni correction for multiple comparisons). Anatomical identification of activation foci was achieved by referring the stereotactic coordinates of the peak activated pixels to the standard Talairach brain atlas [15].

2.5. Visual Analogue Scale (VAS) of Sound Richness
After the PET measurement, the degree of sound richness of each melody with the three types of accompaniments was investigated in each subject. In a quiet room, each subject listened to the stimuli and was required to subjectively mark the VAS (Figure 1) according to the degree of sound richness the subject felt. Three colors (yellow, blue, and red) were used because the lyrics of some songs had a relationship with a specific color, for example, the sea related to blue and the sunset to red. Subjects marked to the right to the degree that they felt that the sound of the music was rich. We measured the distance from the left end to the marked position (mm) and, using the Wilcoxon signed rank test, statistically compared the distance between the three kinds of accompaniments, namely, chord, simple, and complex condition.

3. Results
Regarding the VAS of sound richness, the mean distance from the left end was significantly longer as the accompaniment became more complex (Figure 2): chord condition 54.2 ± 34.2; simple condition 71.3 ± 30.1; complex condition 101.4 ± 31.1 mm (mean ± standard deviation (sd)). We can reasonably conclude that, as expected, the more complex the accompaniment became, the richer the subjects reported the sound.

The results of subtractions providing significant regions activated as the sound became more complex are given in Tables 1, 2, and 3 and Figures 3, 4, and 5. The regions activated during the simple condition but not during the chord condition are listed in Table 1 together with stereotactic coordinates based on the brain atlas of Talairach and Tournoux [15]. These results show areas of relative blood flow changes that emphasize differences between the two conditions and minimize areas that are common to both conditions. Significant increases in relative cortical blood flow were found in the posterior portion of the left inferior temporal gyrus, bilateral fusiform gyri, the medial surface of the bilateral frontal lobes, the right superior parietal lobule, and the left orbital frontal cortex (Table 1, Figure 3). Compared to the chord condition, the complex condition produced significant activation at the posterior portion of the left inferior temporal gyrus, left fusiform gyrus, right medial surface of the occipital lobe, the lateral surface of the left occipital lobe, and the anterior portion of the left middle temporal gyrus (Table 2, Figure 4). Between the complex and simple condition, the former condition significantly activated the posterior portion of the left inferior temporal gyrus, the left fusiform gurus, the left retrosplenial region, the anterior portion of the right middle temporal gyrus, the right cingulate gyrus, and the bilateral cerebellum (Table 3, Figure 5). The important point to note is that the activation of the posterior portion of the inferior temporal gyrus and the fusiform gyrus was observed in all results after every subtraction, that is, simple minus chord, complex minus chord, and complex minus simple condition. The opposite subtraction of chord minus simple, chord minus complex, and simple minus complex conditions revealed almost the same activation pattern. The activation was observed at the bilateral orbital frontal cortex, the bilateral or left superior frontal gyrus, and the right superior temporal gyrus (Tables 4–6, Figures 6–8).

4. Discussion
The findings of this experiment are summarized as follows: as an accompaniment became more complex, (i) the subjects felt that the sound of music was richer and (ii) the fusiform cortex and the posterior portion of the inferior temporal gyrus were activated. In the following paragraphs, we discuss the functional significance of these activated brain regions.

The fusiform cortex might participate in the perception of sound richness. The present study showed that, as the sound became richer, the activation of the fusiform cortex increased. This finding revealed that the degree of the activation of the fusiform cortex was different depending on the degree of the sound richness of the accompaniment in the identical melodies. It is generally accepted that the fusiform cortex processes color recognition, based on the results of a case [16] and a PET activation study [17]. The findings of the present study and previous reports suggest that color information in vision and sound richness in audition might be similarly registered in the brain. In other words, it is possible that similar information from different sensory modalities might be processed within the same brain region and that the visual association cortex might not only be involved in visual processing. Recent studies have revealed that some sensory modalities are related to each other. This phenomenon is called “cross-modal integration” and was observed between taste and audition [18], taste and smell [19–22], taste and color [23], odor and color [24], taste and music [25], pitch and visual size [26, 27], brightness and frequency of vibrotactile stimuli [28], sound and color [29, 30], and vision and audition [31]. It was reported that cross-modal associations are ubiquitously present in normal mental function [25, 32, 33]. Recent research suggests that cortical auditory processing is divided into separate processing streams [31, 34]. Posterior temporoparietal regions, labeled the “where” or “how” stream, may be specialized for processing sound motion and location [31]. Regions anterior and ventral to primary auditory cortex, labeled the “what” stream, may be specialized for processing characteristic auditory features [31]. Neurons in “what” stream respond directly to auditory and visual sensory stimuli and are important for forming the association between auditory and visual objects [31]. Therefore, we may conclude that cross-modal integration also occurs at the fusiform cortex between color and sound richness when listening to music.

In the present study, the posterior portion of the inferior temporal gyrus was also activated. This area is called the lateral occipital complex (LOC) and is known to participate in foreground and background segregation in vision [35]. It was suggested that the LOC also participates in the discrimination between melody and its accompaniment [2]. In our previous study, we considered that the LOC might play a similar role of foreground and background segregation in both vision and audition. This finding reinforced the hypothesis that some association cortices carry out a similar function beyond the differences in sensory modalities (Figure 9). After the perception of sounds at the auditory cortex level, the information might be sent to the LOC and fusiform cortex. The former and the latter might participate in the foreground and background segregation and the recognition of sound richness, respectively, both in vision and audition.

The opposite subtraction, namely, chord minus simple, chord minus complex, and simple minus complex condition, all produced an activation of the bilateral orbital frontal cortex. The functional significance of this region in this experiment is unclear. However, this region is known as a structure within Yakovlev's circuit that participates in emotion and memory. Damage to this region often results in disinhibition, impairment in control over impulsive behavior based on instinct and emotion. It is possible that activation of the orbital frontal cortex was caused by the comfortable and pleasant feeling of listening to familiar nursery songs or by inhibiting the desire to sing along with these familiar melodies.

In summary, the fusiform cortex and the LOC might have a similar function in vision and audition. The fusiform cortex recognizes color and sound richness, and the LOC participates in foreground and background segregation. We may conclude that the association cortices might play a similar role across multiple sensory modalities. Further studies are needed to clarify the multimodal integration of association cortices.

Supplementary Material
Examples of auditory stimuli of chord, simple, and complex condition of Japanese nursery song “Scene of Winter”.

 Conflict of Interests
The authors declare that there is no conflict of interests regarding the publication of this paper.

Figure 1 Visual analogue scale (VAS) for the assessment of subjective impression of sound richness of each musical stimulus. The length of color bar is 140 mm.

Figure 2 Results of VAS of each accompaniment condition. As the accompaniment became more complex, the subjects regarded the sound of musical pieces as being richer.

Figure 3 Simple-chord condition (p &lt; 0.001). ll: lateral surface of left hemisphere; lm: medial surface of left hemisphere; rl: lateral surface of right hemisphere; rm: medial surface of right hemisphere; up: upper surface.

Figure 4 Complex-chord condition (p &lt; 0.001). ll: lateral surface of left hemisphere; lm: medial surface of left hemisphere; rl: lateral surface of right hemisphere; rm: medial surface of right hemisphere; up: upper surface.

Figure 5 Complex-simple condition (p &lt; 0.001). ll: lateral surface of left hemisphere; lm: medial surface of left hemisphere; rl: lateral surface of right hemisphere; rm: medial surface of right hemisphere; up: upper surface.

Figure 6 Chord-simple condition (p &lt; 0.001). ll: lateral surface of left hemisphere; lm: medial surface of left hemisphere; rl: lateral surface of right hemisphere; rm: medial surface of right hemisphere; up: upper surface.

Figure 7 Chord-complex condition (p &lt; 0.001). ll: lateral surface of left hemisphere; lm: medial surface of left hemisphere; rl: lateral surface of right hemisphere; rm: medial surface of right hemisphere; up: upper surface.

Figure 8 Simple-complex condition (p &lt; 0.001). ll: lateral surface of left hemisphere; lm: medial surface of left hemisphere; rl: lateral surface of right hemisphere; rm: medial surface of right hemisphere; up: upper surface.

Figure 9 Diagram of cognitive processing during listening to music with accompaniment.

Table 1 Regions showing significant changes in rCBF by the subtraction of simple minus chord condition.

Anatomical structures	Brodmann area	Talairach coordinate	
z-score	

x
	
y
	
z
	
Posterior portion of inferior temporal gyrus	37	 	 	 	 	
 L	 	−48	−55	−16	5.20	
Fusiform gyrus	 	 	 	 	 	
 L	18/19	−19	−58	−9	4.38	
 R	19	30	−67	−7	4.32	
Medial surface of occipital lobe	17/18	 	 	 	 	
 L	 	−17	−87	−4	3.83	
 R	 	10	−87	11	4.024	
Superior parietal lobule	7	 	 	 	 	
 R	 	33	−53	56	3.32	
Orbital frontal cortex	11	 	 	 	 	
 L	 	−17	50	−16	3.08	
Coordinates x, y, and z are in millimetres corresponding to the atlas of Talairach and Tournoux. The x-coordinate refers to medial-lateral position relative to midline (negative = left); y-coordinate refers to anterior-posterior position relative to the anterior commissure (positive = anterior); z-coordinate refers to superior-inferior position relative to the anterior commissure-posterior commissure line (positive = superior). z-score refers to the maximum pixel of the region. L and R refer to the left and right hemisphere, respectively. 

Table 2 Regions showing significant changes in rCBF by the subtraction of complex minus chord condition.

Anatomical structures	Brodmann area	Talairach coordinate	
z-score	

x
	
y
	
z
	
Posterior portion of inferior temporal gyrus	37	 	 	 	 	
 L	 	−53	−58	−11	4.97	
Fusiform gyrus	 	 	 	 	 	
 L	19/37	−30	−49	−11	3.58	
Medial surface of occipital lobe	 	 	 	 	 	
 R	17	17	−96	2	3.10	
Lateral surface of occipital lobe	 	 	 	 	 	
 L	18	−39	−73	−2	3.00	
Anterior portion of middle temporal gyrus	 	 	 	 	 	
 R	38	35	8	−40	3.96	
Details as for Table 1.

Table 3 Regions showing significant changes in rCBF by the subtraction of complex minus simple condition.

Anatomical structures	Brodmann area	Talairach coordinate	
z-score	

x
	
y
	
z
	
Posterior portion of inferior temporal gyrus	37	 	 	 	 	
 L	 	−60	−58	−7	3.81	
Fusiform gyrus	 	 	 	 	 	
 L	36	−33	−26	−25	4.27	
Retrosplenial region	 	 	 	 	 	
 L	29	−6	−51	18	3.91	
Anterior portion of middle temporal gyrus	 	 	 	 	 	
 R	38	37	8	−40	3.44	
Cingulate gyrus	 	 	 	 	 	
 R	31	10	−28	40	3.29	
Cerebellum	 	 	 	 	 	
 L	 	−51	−49	−38	3.34	
 R	 	39	−64	−32	3.34	
Details as for Table 1.

Table 4 Regions showing significant changes in rCBF by the subtraction of chord minus simple condition.

Anatomical structures	Brodmann area	 Talairach coordinate	
z-score	

x
	
y
	
z
	
Orbital frontal cortex	11	 	 	 	 	
 L	 	−6	26	−16	2.97	
 R	 	5	24	−14	2.73	
Superior frontal gyrus	6/8	 	 	 	 	
 L	 	−24	30	43	3.13	
 R	 	21	19	58	3.29	
Superior temporal gyrus	 	 	 	 	 	
 R	22	51	3	2	3.06	
Cerebellum	 	 	 	 	 	
 L	 	−17	−62	−36	3.82	
 R	 	51	−46	−36	3.43	
Details as for Table 1.

Table 5 Regions showing significant changes in rCBF by the subtraction of chord minus complex condition.

Anatomical structures	Brodmann area	 Talairach coordinate	
z-score	

x
	
y
	
z
	
Orbital frontal cortex	10/11	 	 	 	 	
 L	 	−3	26	−18	5.39	
 R	 	12	64	−11	3.20	
Superior frontal gyrus	 	 	 	 	 	
 L	8	−24	28	50	3.05	
Superior temporal gyrus	 	 	 	 	 	
 R	22	62	−37	7	3.75	
Details as for Table 1.

Table 6 Regions showing significant changes in rCBF by the subtraction of simple minus complex condition 3.

Anatomical structures	Brodmann area	Talairach coordinate	
z-score	

x
	
y
	
z
	
Orbital frontal cortex	11	 	 	 	 	
 L	 	−1	28	−20	4.79	
 R	 	12	32	−18	4.06	
Anterolateral portion of superior frontal gyrus	 	 	 	 	 	
 L	21/22	−48	5	−14	2.97	
Superior temporal gyrus	 	 	 	 	 	
 R	22	62	−37	7	2.90	
Cerebellum	 	 	 	 	 	
 L	 	−51	−37	−25	3.17	
Details as for Table 1.



   
1 Sadie S.   The Grove Concise Dictionary of Music  1994 London, UK The Macmillan Press 
2 Satoh M.  Takeda K.  Nagata K.  Tomimoto H.   The lateral occipital complex is activated by melody with accompaniment: foreground and background segregation in auditory processing Journal of Behavioral and Brain Science  2011 1 3 94 101 10.4236/jbbs.2011.13013 
3 Town S. M.  Bizley J. K.   Neural and behavioral investigations into timbre perception Frontiers in Systems Neuroscience  2013 7, article 88 10.3389/fnsys.2013.00088 
4 Zatorre R. J.  Halpern A. R.  Perry D. W.  Meyer E.  Evans A. C.   Hearing in the mind's ear: a PET investigation of musical imagery and perception Journal of Cognitive Neuroscience  1996 8 1 29 46 10.1162/jocn.1996.8.1.29 2-s2.0-0030025024 23972234 
5 Mirz F.  Pedersen C. B.  Ishizu K.    Positron emission tomography of cortical centers of tinnitus Hearing Research  1999 134 1-2 133 144 10.1016/s0378-5955(99)00075-1 2-s2.0-0032873041 10452383 
6 Klein D.  Zatorre R. J.  Milner B.  Zhao V.   A cross-linguistic PET study of tone perception in Mandarin Chinese and English speakers NeuroImage  2001 13 4 646 653 10.1006/nimg.2000.0738 2-s2.0-0035719911 11305893 
7 Grison B.   Une etude sur les alterations musicales au cours des lesions hemispheriques [M.S. thesis]  1972 (Cited by A. L. Benton, “The amusias” in: M. Critchley and R. A. Henson Eds, Music and the Brain , William Heinemann Medical Books Limited, London, UK, 378–397, 1977) 
8 Hoshina H.  Tabata H.   The Enjoyment of the Application of Harmony  1985 Tokyo, Japan Ongaku-no-Tomo-sha (Japanese) 
9 FINALE 2004 FOR WINDOWS, MakeMusic, Coda Music Technology, CAMEO Interactive, 2004 
10 Satoh M.  Takeda K.  Nagata K.  Hatazawa J.  Kuzuhara S.   Activated brain regions in musicians during an ensemble: a PET study Cognitive Brain Research  2001 12 1 101 108 10.1016/s0926-6410(01)00044-1 2-s2.0-0034910689 11489613 
11 Satoh M.  Takeda K.  Nagata K.  Hatazawa J.  Kuzuhara S.   The anterior portion of the bilateral temporal lobes participates in music perception: a positron emission tomography study American Journal of Neuroradiology  2003 24 9 1843 1848 2-s2.0-0142072541 14561614 
12 Satoh M.  Takeda K.  Nagata K.  Shimosegawa E.  Kuzuhara S.   Positron-emission tomography of brain regions activated by recognition of familiar music American Journal of Neuroradiology  2006 27 5 1101 1106 2-s2.0-33750597663 16687552 
13 Kanno I.  Iida H.  Miura S.    A system for cerebral blood flow measurement using an H2 15 O autoradiographic method and positron emission tomography Journal of Cerebral Blood Flow and Metabolism  1987 7 2 143 153 10.1038/jcbfm.1987.37 2-s2.0-0023272297 3558497 
14 Minoshima S.  Koeppe R. A.  Fessler J. A.    Uemura K.  Lasen N. A.  Jones T.  Kannno I.   Integrated and automated data analysis method for neuronal activation studies using [O-15] water PET Quantification of Brain Function, Tracer Kinetics and Image Analysis in Brain PET  1993 Amsterdam, The Netherlands Excerpta Medica/Elsevier 409 417 
15 Talairach J.  Tournoux P.   Co-Planar Stereotaxic Atlas of the Human Brain  1988 New York, NY, USA Thieme 
16 Damasio A.  Yamada T.  Damasio H.  Corbett J.  McKee J.   Central achromatopsia: behavioral, anatomic, and physiologic aspects Neurology  1980 30 10 1064 1071 10.1212/wnl.30.10.1064 2-s2.0-0018962246 6968419 
17 Corbetta M.  Miezin F. M.  Dobmeyer S.  Shulman G. L.  Petersen S. E.   Attentional modulation of neural processing of shape, color, and velocity in humans Science  1990 248 4962 1556 1559 10.1126/science.2360050 2-s2.0-0025194106 2360050 
18 Simner J.  Cuskley C.  Kirby S.   What sound does that taste? Cross-modal mappings across gustation and audition Perception  2010 39 4 553 569 10.1068/p6591 2-s2.0-77951749556 20515002 
19 Auvray M.  Spence C.   The multisensory perception of flavor Consciousness and Cognition  2008 17 3 1016 1031 10.1016/j.concog.2007.06.005 2-s2.0-47149115730 17689100 
20 Djordjevic J.  Zatorre R. J.  Jones-Gotman M.   Odor-induced changes in taste perception Experimental Brain Research  2004 159 3 405 408 10.1007/s00221-004-2103-y 2-s2.0-11144250344 15526194 
21 Small D. M.  Prescott J.   Odor/taste integration and the perception of flavor Experimental Brain Research  2005 166 3-4 345 357 10.1007/s00221-005-2376-9 2-s2.0-27144557210 16028032 
22 Stevenson R. J.  Tomiczek C.   Olfactory-induced synesthesias: a review and model Psychological Bulletin  2007 133 2 294 309 10.1037/0033-2909.133.2.294 2-s2.0-33847672747 17338601 
23 O'Mahony M.   Williams A. A.  Atkin R. K.   Adapting short cut signal detection measures to the problem of multiple difference testing: the R-Index Sensory Quality in Foods and Beverages  1983 London, UK Chapman 69 80 
24 Demattè M. L.  Sanabria D.  Spence C.   Cross-modal associations between odors and colors Chemical Senses  2006 31 6 531 538 10.1093/chemse/bjj057 2-s2.0-33747818037 16648449 
25 Mesz B.  Trevisan M. A.  Sigman M.   The taste of music Perception  2011 40 2 209 219 10.1068/p6801 2-s2.0-79959506361 21650094 
26 Evans K. K.  Treisman A.   Natural cross-modal mappings between visual and auditory features Journal of Vision  2010 10 1 10.1167/10.1.6 2-s2.0-84891700034 
27 Parise C.  Spence C.   Synesthetic congruency modulates the temporal ventriloquism effect Neuroscience Letters  2008 442 3 257 261 10.1016/j.neulet.2008.07.010 2-s2.0-48749110336 18638522 
28 Martino G.  Marks L. E.   Cross-modal interaction between vision and touch: the role of synesthetic correspondence Perception  2000 29 6 745 754 10.1068/p2984 2-s2.0-0033654271 11040956 
29 Ramachandran V. S.  Hubbard E. M.   Hearing colors, tasting shapes Scientific American  2003 288 5 52 59 2-s2.0-0037513462 12701330 
30 Ward J.  Huckstep B.  Tsakanikos E.   Sound-colour synaesthesia: to what extent does it use cross-modal mechanisms common to us all? Cortex  2006 42 2 264 280 10.1016/s0010-9452(08)70352-6 2-s2.0-33644828249 16683501 
31 Beauchamp M. S.  Lee K. E.  Argall B. D.  Martin A.   Integration of auditory and visual information about objects in superior temporal sulcus Neuron  2004 41 5 809 823 10.1016/s0896-6273(04)00070-4 2-s2.0-1542268973 15003179 
32 Hubbard E. M.  Ramachandran V. S.   Neurocognitive mechanisms of synesthesia Neuron  2005 48 3 509 520 10.1016/j.neuron.2005.10.012 2-s2.0-27644487867 16269367 
33 Cytowic R. E.  Eagleman D. M.   Wesnesday is Indigo Blue: Discovering the Brain of Synesthesis  2009 Cambridge, Mass, USA MIT Press 
34 Rauschecker J. P.  Tian B.   Mechanisms and streams for processing of ‘what’ and ‘where’ in auditory cortex Proceedings of the National Academy of Sciences of the United States of America  2000 97 22 11800 11806 10.1073/pnas.97.22.11800 2-s2.0-0034710886 11050212 
35 Grill-Spector K.  Kushnir T.  Edelman S.  Itzchak Y.  Malach R.   Cue-invariant activation in object-related areas of the human occipital lobe Neuron  1998 21 1 191 202 10.1016/s0896-6273(00)80526-7 2-s2.0-0032126772 9697863 



